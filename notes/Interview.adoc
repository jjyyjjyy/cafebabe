= Interview
:icons: font
:source-highlighter: highlightjs
:highlightjs-theme: idea
:hardbreaks:
:sectlinks:
:sectnums:
:stem:
:toc: left
:toclevels: 3
:toc-title: 目录
:tabsize: 4
:docinfo: shared

== Java基础

[qanda]
Java基本数据类型有哪些? 各占多少字节?::
* byte `1`
* short `2`
* int `4`
* long `8`
* boolean `1`
* char `2`
* float `4`
* double `8`
`|` 和 `||` 的区别?::
* `||` 是逻辑运算符, 短路操作, 如果左边是true, 则右边不会执行.
* `|` 是位运算符, 左右两边都会执行.
`>>` 和 `>>>` 的区别?::
* `>>` 带符号右移, 向右移动时使用首位的值来填充.
* `>>>` 无符号右移, 首位固定用零填充.
访问权限修饰符有哪些?::
private < default < protected < public
* `private` : 只能在类的内部访问.
* `default` : 只能被同一个包中其他类访问, 且子包不能访问.
* `protected` : 可以被子类或同一个包中其他类访问.
* `public` : 可以被任意类访问.
重载和重写的区别?::
* 重载发生在同一个类中:
** 方法名称相同.
** 方法参数列表不同.
** 方法抛出的异常, 返回值类型和访问修饰符都可以不同.
* 重写发生在子类中:
** 方法名称相同.
** 参数列表相同.
** 子类方法的返回值类型可以是父类返回值类型或其子类.
** 子类抛出的Checked异常类型可以是父类方法抛出的Checked异常类型或其子类, 或者不抛.
** 子类方法的访问修饰符必须大于等于父类.
String, StringBuilder, StringBuffer的区别?::
* `String` 是不可变类, 每次修改字符串都会生成一个新的String对象.
* `StringBuilder` 和 `StringBuffer` 都是可变对象, 可以修改其内部存储的字符串.
* `StringBuffer` 是线程安全的, `StringBuilder` 不是线程安全的.
new String("abc")创建了几个对象?::
两种情况:
* 如果常量池已经存在abc这个常量, 则只在堆中创建一个String对象.
* 如果常量池不存在abc这个常量, 则会先把abc放入常量池, 然后在堆中创建一个String对象, 一共两个对象.
String为什么要设计成不可变的?::
* *设计角度*: 相同的字符串字面量会指向字符串常量池同一个对象, 如果String对象内部可以改变, 则改动了一个字符串值, 会影响系统中指向该字符串常量的字面量.
* *安全角度*: String广泛运用在网络连接参数/反射等场景, 如果String支持修改自己内部的值, 则会出现一系列系统安全问题.
* *性能角度*: 因为字符串不可变, 所以可以缓存计算过的对象hashcode值, 提升性能.
Checked和UnChecked异常的区别?::
* Checked异常为继承了 `Exception` 类但不是 `RuntimeException` 的子类的异常, 需要调用方手动处理.
* UnChecked异常为继承了 `RuntimeException` 或 `Error` 的异常, 对于UnChecked异常程序可以手动捕获, 也可以不处理.
谈谈对多态的理解?::
多态是指父类引用指向子类对象, 即在程序运行时才能动态获取到引用对象的实际类型.
抽象类和接口的区别?::
* 抽象类可以有构造方法, 接口不行.
* 接口类中的变量只能是 `public static final` 常量类型.
* 一个类只能继承一个抽象类, 但是可以实现多个接口.
* 类继承表达的是 `is-a` 的关系, 表示子类和父类是同一类的类型. 接口实现表达的是 `like-a` 的关系, 表示子类具备父类接口定义的行为.
静态内部类和成员内部类的区别?::
* 成员内部类
** 成员内部类的变量和方法不能声明为静态的, 因为静态成员的访问不需要外部类的对象实例, 这不符合内部类的设计初衷.
** 成员内部类可以引用外部类的非静态属性及方法.
* 静态内部类
** 静态内部类的属性和方法可以声明为静态和非静态的.
** 静态内部类只能引用外部类的静态变量或方法.
为什么匿名内部类引用的外部局部变量的值为final修饰?::
生成的匿名内部类会拷贝一份局部变量的值, 如果外部修改了局部变量的值会导致匿名内部类对象中的值不同, 所以用final修饰禁止修改.
Object类有哪些方法?::
* hashcode
* equals
* clone
* toString
* wait
* notify
* notifyAll
equals和hashCode方法重写规则?::
* hashCode()相等, equals()不一定返回true.
* equals()返回true, hashCode()一定要相等.
泛型中extends和super的区别?::
* extends为上界通配符.
* super为下界通配符.
* 上界 `<? extends T>` 不能往里存，只能往外取
* 下界 `<? super T>` 不影响往里存，但往外取只能放在Object对象里
* *PECS(Producer Extends Consumer Super)原则*: 频繁往外读取内容的, 适合用上界Extends; 经常往里插入的, 适合用下界Super.
获取泛型类型的方法?::
`((ParameterizedType) getClass().getGenericSuperclass()).getActualTypeArguments()[0]`
创建对象有哪些方式?::
* new
* Object#clone()
* Class#newInstance()
* Constructor#newInstance()
* 反序列化
* Unsafe.allocateInstance
getMethods()和getDeclaredMethods()的区别?::
* `getMethods()` 获取本类以及从父类继承过来的public方法.
* `getDeclaredMethods()` 只获取本类的方法.
Class.forName()和ClassLoader#loadClass()的区别?::
`Class.forName()` 会执行类的静态代码块, `ClassLoader#loadClass()` 不会.
`Class#getResourceAsStream` 和 `ClassLoader#getResourceAsStream` 的区别?::
* `Class#getResourceAsStream` 为使用加载该类的类加载器加载文件:
** 不以 `/` 开头时为在该类所在路径下加载文件.
** 以 `/` 开头时为在 `classpath` 下加载文件.
* `ClassLoader#getResourceAsStream` : 为用指定类加载器加载文件.
`ClassNotFoundException` 和 `NoClassDefFoundError` 有什么区别?::
* `ClassNotFoundException` 是Exception类型, `NoClassDefFoundError` 是Error类型.
* 使用 `Class.forName()` / `ClassLoader#loadClass()` / `ClassLoader#findSystemClass()` 等 *加载* 类时找不到类就会抛出 `ClassNotFoundException` ,当编译成功但 *运行* 时(调用该类的一个方法或者new一个实例时)找不到类或者初始化static成员时有异常则会抛出 `NoClassDefFoundError` 异常.
Java类初始化顺序?::
. 父类静态变量
. 父类静态代码块
. 子类静态变量
. 子类静态代码块
. 父类成员变量
. 父类构造代码块
. 父类构造函数
. 子类成员变量
. 子类构造代码块
. 子类构造函数
var和val的区别?::
var表示可变变量, val为非标准关键字, 表示不可变变量.
Java静态代理和动态代理的区别?::
静态代理的代理实现类在编译期就已经确定, 无法在程序运行时期修改; 动态代理是在程序运行期通过反射生成代理类的代码, 具体实现方式为JDK动态代理(实现接口)和CGLIB动态代理(继承父类).
Java中Connection为什么要close?::
及时释放数据库链接, 减少资源消耗. (如果没有显式close, 也会被gc)
BIO和NIO的区别?::
* BIO属于同步阻塞模型, 业务线程读写请求过程中会一直等待数据到达(阻塞), 业务操作完成后才会继续执行后续任务(同步).
* NIO属于IO多路复用模型, 通过epoll/kqueue系统调用批量查询可用的socket(非阻塞), 然后通过单读的线程进行读写操作(同步), 节省了read阻塞阶段的耗时.
* BIO基于字节流读写请求, NIO使用缓冲区读写请求.
Java NIO有哪些Buffer类型?::
* ByteBuffer(字节缓冲区): 用于读写字节数据.
* ShortBuffer(短整型缓冲区): 用于读写短整型数据.
* IntBuffer(整型缓冲区): 用于读写整型数据.
* LongBuffer(长整型缓冲区): 用于读写长整型数据.
* CharBuffer(字符缓冲区): 用于读写字符数据.
* FloatBuffer(浮点型缓冲区): 用于读写浮点型数据.
* DoubleBuffer(双精度浮点型缓冲区): 用于读写双精度浮点型数据.
Buffer的四个核心属性?::
* capacity: 缓冲区的容量, 不可修改.
* limit: 当前可操作的缓冲区的长度.
* position: 当前操作的索引.
* mark: 标记位置, 可通过 `reset()` 恢复position为mark的位置.
`flip()` 和 `rewind()` 方法的使用场景?::
* `flip()` 方法用于写完后读取刚刚写入缓冲区内容的场景, 如写header+body后读取整个header+body内容.
* `rewind()` 方法用于重复读取缓冲区内容的场景.
SelectionKey的事件类型?::
* OP_CONNECT(仅客户端SocketChannel): 请求连接成功.
* OP_ACCEPT(仅服务端ServerSocketChannel): 请求连接就绪.
* OP_READ: 读缓冲区中存在数据可以读取.
* OP_WRITE: 写缓冲区中存在空间可以写入.


== Java集合

[qanda]
Java容器有哪些?::
* `List` 列表/链表
** Vector
** ArrayList
** LinkedList
** CopyOnWriteArrayList
* `Queue` 队列
** ArrayDeque
** ArrayBlockingQueue
** LinkedBlockingQueue
** DelayQueue
** SynchronousQueue
** LinkedTransferQueue
** ConcurrentLinkedQueue
** ConcurrentLinkedDeque
* 堆
** PriorityQueue
** PriorityBlockingQueue
* `Set` 集合
** HashSet
** LinkedHashSet
** CopyOnWriteArraySet
** ConcurrentSkipListSet
* `Map` 散列表
** HashTable
** HashMap
** LinkedHashMap
** IdentityHashMap
** ConcurrentHashMap
** WeakHashMap
* 有序树
** TreeMap
** ConcurrentSkipListMap
ArrayList和LinkedList的区别?::
* `ArrayList` 底层使用数组存储元素, `LinkedList` 使用双向链表.
* `ArrayList` 插入和删除时间复杂度为stem:[O(n)], 查找为stem:[O(1)]. `LinkedList` 查找和删除时间复杂度为stem:[O(n)], 插入为stem:[O(1)].
* `ArrayList` 适合从中间插或者尾插, `LinkedList` 更适合头插.
* `LinkedList` 每个元素需要维护前后元素的引用, 所以内存占用比 `ArrayList` 大.
* 都不是线程安全的.
有哪些Map实现类?::
* HashMap `查找键值对`
* LinkedHashMap `保证key按照插入/查找的顺序输出`
* TreeMap `红黑树, 按照自定义顺序遍历key`
* ConcurrentSkipListMap `线程安全的有序树, 基于跳表实现`
* ConcurrentHashMap `线程安全`
* WeakHashMap `存取弱引用对象的哈希表`
* IdentityHashMap `使用System.identityHashCode()计算hashCode, 使用==判断key是否相同`
HashMap和HashTable的区别?::
* HashTable线程安全; HashMap线程不安全.
* HashTable默认初始长度为11; HashMap默认初始长度为16, 且总为2的幂.
* HashTable扩容后为stem:[2n+1]; HashMap扩容后为stem:[2n].
* HashMap的kv可以为null, 放在数据索引为0的位置; HashTable的kv均不能为null.
* HashMap因hash冲突产生的链表长度大于8后会转成红黑树; HashTable不会.
JDK中有哪些保持key有序的Map?::
* LinkedHashMap: 按照插入顺序或者读取顺序排列key.
* TreeMap: 按照key的大小排好序.
* ConcurrentSkipListMap: 线程安全.
有哪些散列函数?::
* 求和: 将每一位的ascii值相加得到哈希值.
* 多项式求和: 以一个素数(31)为底, 多项式求和: stem:[sum_(i=0)^(n-1)"key"[n-i-1\]xx31^i] , 如 stem:[h=k_0+k_1xx31+k_2xx31^2+...+k_(n-1)xx31^(n-1)]
* CRC16/CRC32.
散列表解决hash冲突的方法?::
* 拉链法: 如果hash值落在相同的槽位上, 则将该槽位元素转成链表, 将冲突的元素放在已有元素的后面. `HashMap`
* 开放地址法: 如果hash所在的槽位已有元素, 则将元素存放到下一个为空的槽位上. `ThreadLocal.ThreadLocalMap`
* 再哈希法: 计算多次hash值, 增加数据离散程度.
为什么HashMap的长度始终是2的幂?::
stem:[x%2^n=x&(2^n-1)] 用与运算代替模运算, 效率更高.
HashMap的实现原理?::
. 计算key的hash值: `(h = key.hashCode()) ^ (h >>> 16)` hashCode的前16位和后16位异或.
. 根据hash值计算出存放该key的槽位(`hash & (length - 1)`)
* 如果table为空, 则初始化table, 直接插入.
* 如果索引处为空, 直接插入.
* 如果索引处不为空, 则根据hash和key比较找到已有的key.
** 如果key找到了则直接更新value.
** 如果key没有找到, 则判断当前node是否为红黑树的node还是链表node, 插入.
** 如果当前node属于链表且长度大于8且哈希表长度大于64, 则转成红黑树, 如果小于64说明元素分散不够均匀, 会扩容一次.
* 插入后如果table长度超过了阈值(capacity*loadFactor), 则长度扩容两倍, 然后重新计算每个元素的槽位. 因为 stem:[x&(2n-1)=(x&(n-1) or 2xxx&(n-1))], 所以扩容后原来的索引stem:[i]只会移动到新的数组索引stem:[i或2i]处, 通过 stem:[i&n]就可以计算出新索引为stem:[i or 2i].
HashSet的实现原理?::
内部维护了一个HashMap, 每次添加元素的时候, key为待添加的元素, value为一个单例的Object对象.
HashSet在向map中put的时候value为什么不存null还是一个固定的Object对象?::
如果是第一次插入key为null的元素, 返回null, 第二次插入, 返回PRESENT对象, 可以通过返回值区分set中是否存在null元素.
LinkedHashMap的实现原理?::
. `LinkedHashMap` 可以设置按照插入顺序(默认)还是访问顺序对key排序.
. `LinkedHashMap` 每个元素有前置和后继节点, 标识插入/访问的顺序关系, `LinkedHashMap` 内部也保存了头结点和尾结点的引用.
. 每次插入/删除的时候, 会把尾结点的后继节点设置为新节点, 然后把尾结点设置为当前节点.
. 遍历的时候, 从 `LinkedHashMap` 内部保存的头结点开始遍历.
如何使用LinkedHashMap实现LRU缓存?::
. 继承 `LinkedHashMap` , 设置 `accessOrder` 属性为true.
. 如果需要限制缓存容量, 重写 `removeEldestEntry` 方法即可.
fail-fast和fail-safe分别代表什么?::
* `fail-fast` 输赢迭代器遍历一个集合对象的时候, 如果遍历这个集合的过程中对集合做了修改会抛出 `ConcurrentModifiedException` .
* `fail-safe` 在遍历时先复制原有集合, 然后在拷贝的集合上进行遍历.

== JUC

[qanda]
创建线程的方法?::
* 实现Runnable接口.
* 继承Thread类.
* 实现Callable接口.
synchronized关键字的使用?::
* 修饰实例方法
* 修饰静态方法
* 修饰代码块
sleep和wait的区别?::
* 定义不同: sleep为Thread类的方法, wait为Object类的方法.
* 作用对象不同: sleep作用于当前线程, wait作用于持有指定的对象锁的线程.
* sleep不会释放锁, 当前线程进入 `TIMED_WAITING` 状态, wait会释放锁且进入 `WAITING/TIMED_WAITING` 状态.
* sleep可以在任意代码块里, wait必须在同步代码块里.
为什么wait方法必须在同步代码块里?::
. 释放锁的前提是要先持有锁.
. 避免CPU切换到另外一个线程先执行了notify方法.
为什么wait方法定义在Object里而不是Thread?::
因为synchronized可以锁住任意对象, 而锁住的对象需要有wait/notify方法来实现线程间通信.
synchronized和volatile的区别?::
* 功能不同: `synchronized` 用于锁定临界区, 只有持有锁的线程才能访问临界区. `volatile` 用于变量, 标识该变量的值一直需要从主存读取.
* 使用不同: `volatile` 只能用于变量上, `synchronized` 可以用作实例方法/静态方法和代码块上.
* 语义不同: `volatile` 只保证可见性和禁止指令重排序, `synchronized` 保证可见性和原子性.
线程的状态流转?::
* NEW -> RUNNABLE: Thread#start()方法.
* RUNNABLE -> BLOCKED: 未争取到锁被阻塞.
* BLOCKED -> RUNNABLE: 争取到锁.
* RUNNABLE -> WAITING/TIMED_WAITING: Object#wait, Thread#join, Thread.sleep, LockSupport.park.
* WAITING/TIMED_WAITING -> RUNNABLE: Object#notify, Object#notifyAll, LockSupport.unpark.
* RUNNABLE -> TERMINATED: run方法执行结束.
Thread类run()和start()区别?::
* `run()` : 执行具体的工作.
* `start()` : 启动一个新的线程, 该线程去执行具体的工作.
Thread.join()有什么作用?::
等待线程执行完
终止一个线程的方法有哪些?::
* 使用一个volatile修饰的标志位while循环判断是否终止.
* 调用Thread#interrupt()方法
** 如果线程处于运行状态, `Thread.currentThread().isInterrupted()` 方法返回true, 线程内部判断这个标志位跳出方法.
** 如果线程处于阻塞状态, 则会抛出InterruptedException.线程内部可以捕获该异常终止方法.
* 调用Thread#stop()方法, 此方法会释放所有子线程的锁, 但可能会导致线程安全问题.
守护线程和本地线程的区别?::
当JVM内部只剩守护线程时, JVM就会自动退出.
请描述synchronized锁的升级过程?::
* 无锁: 当线程首次进入同步代码块时, 不需要获得锁, 处于无锁状态.
* 偏向锁: 当线程反复进入该同步代码块时, 会在锁对象header中记录该线程id, 下次进入时无需获得锁.
* 轻量级锁: 当有其他线程竞争锁时, 会升级成轻量级锁, 通过CAS操作获得锁, 失败后重试(自旋).
* 重量级锁: 自旋超过一定次数后仍未获得锁, 则会升级成重量级锁, 通过操作系统的Mutex来实现线程同步.
CAS的ABA问题如何解决?::
* AtomicStampedReference
* AtomicMarkableReference
基于AQS实现的锁有哪些?::
* ReentrantLock
* ReentrantReadWriteLock
* Semaphore
* CountDownLatch
线程池初始化参数的解释?::
* `int corePoolSize` : 核心线程数个数
* `int maximumPoolSize` : 最大线程数个数
* `long keepAliveTime` : 核心线程之外的线程存活时间
* `TimeUnit unit` : KeepAliveTime时间单位
* `BlockingQueue<Runnable> workQueue` : 线程池所用的阻塞队列类型
* `ThreadFactory threadFactory` : 线程创建的工厂类
* `RejectedExecutionHandler handler` : 最大线程满载后的线程提交后拒绝策略
线程池中阻塞队列有哪些?::
* ArrayBlockingQueue
* LinkedBlockingQueue
* SynchronousQueue
* LinkedTransferQueue
* DelayQueue
线程池的工作原理?::
. 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务；
. 如果当前线程池中的线程数目大于等于corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务；
. 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理；
. 如果线程池中的线程数量大于corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。
线程池的拒绝策略?::
* AbortPolicy(默认): 丢弃任务并抛出 `RejectExecutionException` 异常.
* DiscardPolicy: 丢弃任务, 但是不抛出异常.
* DiscardOldestPolicy: 丢弃队列最前面的任务, 然后重新提交被拒绝的任务.
* CallerRunsPolicy: 由调用线程处理该任务.
Timer类的缺点?::
* 一个任务执行时间长将会影响后面的任务.
* 前面的任务抛出异常, 后面的任务会执行不了.
Tomcat线程调度流程?::
Tomcat自定义了阻塞队列和Executor的实现, 处理的流程与JDK线程池稍有不同.
. 如果当前线程数小于核心线程数(minSpareThreads, 默认10), 则创建一个新的线程.
. 如果当前线程数大于核心线程数, 并且小于最大线程数, 仍然创建一个新的线程.
. 如果当前工作线程数小于总线程数, 说明有空闲线程, 加入到队列中.
. 如果当前线程数大于最大线程数, 则加入到队列中, 等待有空闲的工作线程执行该任务.
. 如果加入到队列失败, 则抛出异常.
ThreadLocal内存泄漏问题?::
* 何时会发生泄漏: 持有ThreadLocal对象已经被回收, 但是线程还处于运行状态且Value没有被remove掉, threadLocalMap中还存在ThreadLocal设置的Entry和Value(Entry包含Key和Value, key为弱引用会在GC后被回收, 但是Entry和Value不会).
* ThreadLocal协助解决内存泄漏的方式:
. ThreadLocal的Entry将key(也就是ThreadLocal对象本身)设置为弱引用, 防止但Thread持有该对象的引用导致该ThreadLocal对象始终无法回收.
. 每次set/remove时会遍厉槽位, 清除get()为null的槽位(获取key为null代表该ThreadLocal已被回收), 一直遍历到不为null的槽位.
* 正确的使用ThreadLocal: ThreadLocal设置为类常量强引用, 线程设置完value后在使用结束后remove掉, 防止thread不停止的情况下value不会回收从而导致内存泄漏.

== JVM

[qanda]
JVM内存区域的划分?::
* 线程私有:
** 程序计数器: 存储当前线程执行的字节码的指令地址.
** 虚拟机栈: 存放当前线程的栈帧.每个栈帧对应一个被调用的方法, 栈帧中包括局部变量表, 操作数栈, 方法返回地址等信息.当线程执行一个方法时, 就会创建一个栈帧压栈, 当方法执行完毕, 便会将栈帧出栈.
** 本地方法栈: 存储当前线程调用的本地方法的栈帧.
* 线程共享:
** 堆: 存储对象数据.
** 方法区: 存储类的信息, 静态变量, 常量, 编译后的代码等.
强/软/弱/虚引用的区别?::
* *强引用* : 强引用的对象不会被立即回收.
* *软引用(SoftReference)* : 满足以下 `ReferencePolicy` 的回收条件时, 会将软引用关联的对象列入垃圾回收范围回收 (详见 `ReferenceProcessor::process_soft_ref_reconsider_work` 方法).
** NeverClearPolicy: 从不回收软引用对象.
** AlwaysClearPolicy: 一直回收软引用对象.
** LRUMaxHeapPolicy(开启c2/jvmci编译器下默认策略): 如果clock-timestamp>(最大堆容量-上次gc后堆使用的空间大小)/1MB*SoftRefLRUPolicyMSPerMB(默认1000), 会回收软引用, 否则不会回收.
** LRUCurrentHeapPolicy(禁用c2&jvmci编译器下默认策略): 如果clock-timestamp>上次gc后堆可用空间大小/1MB*SoftRefLRUPolicyMSPerMB(默认1000), 会回收软引用, 否则不会回收.
* *弱引用(WeakReference)* : 垃圾回收时会回收弱引用对象.
* *虚引用(PhantomReference)* : 无法通过虚引用来获取被引用的对象, 该对象在被回收的同时会将该对象放入ReferenceQueue, 外部可以通过从Queue中poll出元素来接收到对象被回收的事件, 如果该对象是 `Cleaner` 类型, 则会执行clean方法.
对象创建的过程?::
. new指令的参数是否能在常量池中定位到一个类的符号引用, 如果这个符号引用代表的类没有被加载过, 则执行相应的类加载过程.
. 为对象分配内存.
. 初始化字段值.
. 设置对象头.
. 执行构造函数.
JVM对象的结构?::
. 对象头.(MarkWord+ClassPointer)
. 对象实例数据.
. 对齐填充.
对象头的内容?::
. MarkWord
. 类型指针: 指向类型元数据的指针.
. 如果是数组, 还需要记录数组长度.
对象的访问方式?::
* 直接指针访问(HotSpot): reference中储存的是对象的实例地址. 可以通过reference中的地址直接访问到对象.(对象实例数据中存储了对象类型数据的指针)
** 好处: 节省一次指针定位的开销, 速度快.
* 句柄访问: 堆中划分一块内存作为句柄池, 句柄池中存储了对象的实例数据地址和对象类型数据地址. reference中存储的是句柄地址.
** 好处: 在对象被移动的时候只会修改句柄中的对象实例数据地址, 而不会修改reference.
OOM有哪些类型?::
* 堆内存溢出. `Java heap space`
* 无限创建动态代理对象导致方法区内存溢出. `Metaspace`
* 分配直接内存失败. `Direct buffer memory`
* 内存不足导致线程无法创建. `unable to create new native thread`
* 花费超过98%的时间GC而只得到不到2%的内存.`GC overhead limit exceed`
GC的分类?::
* Minor GC/Young GC: 新生代的收集.
* Major GC/Old GC: 老年代的收集(CMS).
* Mixed GC: 收集整个新生代和部分老年代(G1).
* Full GC: 整个Java堆和方法区的收集.
Young GC发生的场景有哪些?::
* Eden区满.
* 触发Full GC前会先执行一次 `Young GC` .
Full GC发生的场景有哪些?::
* 老年代满了或者达到设定的阈值.
* CMS回收失败, 发生 `promotion failed/concurrent mode failure` .
* 从新生代要放入老年代的对象平均大小超过了老年代剩余空间.
如何标记对象可以被回收?::
* 引用计数法: 在对象中添加一个引用计数器, 每有一个地方引用它时, 计数器值加一, 引用失效时, 计数器值减一. 当计数器值为0时, 该对象就是可以被回收的.
* 可达性分析: 定义一些类型的对象为根对象, 根对象本身和根对象持有的其他对象的引用(包括该对象持有的其他对象的引用)都是不可回收的, 其他对象就是可以被回收的.
哪些对象属于GC Root?::
* 栈中的变量引用的对象, 包括局部变量, 方法参数.
* 静态变量引用的对象.
* 运行中的线程对象.
* 被同步锁(synchronized)持有的对象.
* `System ClassLoader` 加载的Class对象, SystemClassLoader, 一些基础异常类等.
* JNI(native方法)引用的对象.
* JMXBean.
* JVMTI中注册的回调.
* 本地代码缓存.
有哪些垃圾回收算法?::
* 标记清除: 首先标记需要回收的对象, 然后统一把被标记的对象依次清除, 一般用于老年代.
** 缺点① 如果堆中大部分对象需要被回收, 则标记和清除执行时间会较长.
** 缺点② 内存中会出现大量不连续的碎片, 分配大对象时如无法找到足够的连续内存, 则会触发一次FULL GC.
* 标记复制: 将内存区域分为两部分, 每次只使用其中的一块, 回收时把存活的对象移动到另一块内存, 然后直接清空原先的块, 一般用于新生代.
** 优点① 没有内存碎片.
** 缺点① 浪费了一半的内存可用空间.
** 缺点② 如何对象存活率高, 那么拷贝对象的成本也高.
* 标记整理: 将存活的对象统一移动到一端, 然后直接清理掉边界之外的内存.
** 优点① 没有内存碎片.
** 缺点① 移动对象会发生STW, 会暂停用户线程.
* 分代收集: 根据不同的内存区域, 使用不同的回收算法.
有哪些垃圾回收器?::
* Young区:
** Serial
** ParNew
** Parallel Scavenge Young
* Old区:
** Serial Old
** Parallel Old
** CMS
* 混合回收:
** G1
** ZGC
* 不回收:
** Epsilon
新生代分为哪几个区?::
1个Eden, 两个Survivor.
新生代Eden区和Survivor区的默认比例? 如何修改?::
默认 stem:[8:1:1], 通过 `-XX:SurvivorRatio` 参数修改Eden区与Survivor区大小的比例, 默认为8.
堆内存新生代和老年代的默认比例? 如何修改?::
默认 stem:[1:2], 通过 `-Xmn` 设置新生代的大小, 或者 `-XX:NewRatio` 设置Old区与Young区大小的比例, `-Xmn` 优先级更高.
并发扫描时如何解决存活对象错误标记为死亡?::
灰色对象切断一个白色对象引用, 同时一个黑色对象新增这个白色的引用.
* 增量更新: 当一个黑色对象插入一个白色对象的引用时, 将这个黑色对象变为灰色对象. `CMS`
* 原始快照: 当一个灰色对象删除一个白色对象的引用时, 将引用关联的对象变为灰色对象. `G1`
对象何时进入老年代?::
* survivor区中的对象年龄超过了 `-XX:PretenureSizeThreshold` 设置的值. (默认为6)
* Young GC时Eden区的对象放不进survivor区, 会直接进入老年代.
CMS采用哪种回收算法?::
CMS使用标记-清除算法回收老年代.
CMS何时触发FullGC?::
* `promotion failed` : YoungGC回收后将一部分对象晋升到老年代, 但是老年代空间不足, 触发FullGC.
** 优化思路1: 调大Xmn
** 优化思路2: 调大老年代晋升年龄.
* `concurrent mode failure` : CMS并发Old GC时应用线程有新的对象放到老年代但是剩余的老年代空间不足, 升级为FullFC.
** 优化思路1: 调低CMS Old GC阈值: `-XX:+UseCMSInitiatingOccupancyOnly -XX:CMSFullGCsBeforeCompaction=60`
CMS怎么解决内存碎片问题?::
* (JDK8及以后版本后此参数已过时无用) CMS提供 `-XX:+UseCMSCompactAtFullCollection` 开关参数, 用于在CMS Old GC时开启内存碎片的合并整理过程.
* CMS提供 `-XX:CMSFullGCsBeforeCompaction` 参数, 用于设置在执行指定次数不整理空间的Full FC后, 在下一次Full GC前整理内存碎片.
CMS回收的步骤?::
. 初始标记
. 并发标记
. 重新标记
. 并发清除
G1回收的步骤?::
. 初始标记
. 并发标记
. 最终标记
. 筛选回收
Young GC频繁原因?::
* 新生代内存空间设置过小.
* 大量生成生命周期短的对象.
* `PretenureSizeThreshold` 设置过高导致对象不会进入老年代.
Young GC慢的原因?::
* 新生代内存空间设置过大, 回收需要消耗很多时间.
* 对象引用链比较长, 扫描时间长.
* 新生代survivor设置的比较小, 回收后存活的对象只能移动到老年代, 造成移动对象开销.
* 内存分配担保失败, MinorGC升级为Full GC.
* 采用serial收集器回收新生代, 串行执行, 效率较低.
频繁GC问题如何定位?::
* `jstat -gc <pid> [interval(ms)]`
** `S0C` 第一个survivor区大小.
** `S1C` 第二个survivor区大小.
** `S0U` 第一个survivor区已使用大小.
** `S1U` 第二个survivor区已使用大小.
** `EC` Eden区大小
** `EU` Eden区已使用大小.
** `OC` Old区大小.
** `OU` Old区已使用大小.
** `MC` Metaspace区大小.
** `MU` Metaspace区已使用大小.
** `CCSC` 压缩类空间大小.
** `CCSU` 压缩类空间已使用大小.
** `YGC` YoungGC次数.
** `YGCT` YoungGC总消耗时间.
** `FGC` FullGC次数.
** `FGCT` FullGC总消耗时间.
** `GCT` GC总消耗时间.
* jcmd
** `jcmd <pid> Thread.print` 打印线程栈.
** `jcmd <pid> GC.class_histogram | head -20` 查看各个类的所有实例对象大小, 执行时会触发Full GC.
** `jcmd <pid> GC.run` 执行一次 `System.gc()` .
** `jcmd <pid> VM.heap_info` 打印堆和方法区占用大小.
** `jcmd <pid> VM.flags` 查看JVM启动参数.
** `jcmd <pid> GC.heap_dump <file>` dump JVM进程.
* jmap
** `jmap -histo:live <pid> | head -20` 查看各个类的所有实例对象大小, 执行时会触发Full GC.
** `jmap -dump:live,format=b,file=<file> <pid>` dump JVM进程.
** `jmap -heap <pid>` 打印堆各个区占用大小.
* core dump分析
* gc日志上传到 https://gceasy.io 分析, 根据报告调整各个区内存大小.
如何进行堆内存dump?::
* jmap: `jmap -F -dump:live,file=jmap.hprof <pid>`
* jcmd: `jcmd <pid> GC.heap_dump jmap.hprof`
* 自动dump: `-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=<path/to/dump>`
* JMX客户端工具
* 编程式调用: `HotSpotDiagnosticMXBean`
内存溢出和内存泄漏的区别?::
* 内存泄漏: 内存一直占用但不释放.
* 内存溢出: 申请内存时, 没有足够的内存使用.
哪些情况会出现内存泄露?::
* 静态集合中一直填入大量数据且不删除.
* 未关闭的IO流.
* 哈希表使用可变对象作为key. 修改变量属性后hash值发生改变, 此时如果从hash表中删除该key会找不到而删除失败.
* 一个生命周期短的对象被生命周期长的对象所持有, 则会导致该对象无法被回收.
如何找到JVM CPU占用高的原因?::
* top+jstack
. `jps` 查看JVM进程 `PID`.
. `top -Hp PID` 查看该JVM进程内线程资源占用情况.找到CPU占用资源高的线程 `TID`.
. `printf '%x\n' TID` 将线程id转成16进制数.
. `jstack PID | grep TID -A 10` 查看该线程所在堆栈, 检查堆栈所在代码上的错误.
* async-profiler
JVM的类加载器?::
* Bootstrap ClassLoader: 加载jre/classes下的类以及rt.jar.
* Ext ClassLoader: 加载jre/lib/ext下的类以及 `java.ext.dirs` 系统变量指定的路径下的类.
* App ClassLoader: 加载classpath下的类.
JVM的双亲委派机制?::
. 如果之前已经加载过, 则直接返回原来已经加载好的类.
. 委托给父加载器去加载, 如果父类加载不到则自己去加载.
如何实现双亲委派机制?::
继承 `ClassLoader` , 重写 `findClass` 方法.
如何破坏双亲委派机制?::
* 继承ClassLoader, 重写LoadClass方法, 在LoadClass方法里不尝试去用父类加载器加载类. `Tomcat`
* Java的SPI机制: `DriverManager` 在JDK里, 使用 `BootstrapClassLoader` 加载不到驱动类, 所以使用 `Thread.currentThread().getContextClassLoader()` 获取到 `AppClassLoader` 来加载类. `JDBC`
类加载的过程?::
. 加载: 将字节码加载到方法区, 生成Class对象.
. 链接
.. 验证: 确保该类的字节码文件所包含的信息是否符合当前虚拟机的要求.
.. 准备: 为静态变量分配内存, 设置该类型的初始值. static final变量设置默认值.
.. 解析: 将常量池中的符号引用替换为直接引用.
. 初始化: 初始化静态变量, 执行静态代码块.
JMM?::
* 原子性
* 可见性
* 有序性

== Maven

[qanda]
Maven的生命周期是怎样的?::
. Clean
. Default
. Site
Maven的坐标是由什么构成的?::
* group-id: 组织名称
* artifact-id: 项目名称
* version: 项目版本
Maven依赖的范围有哪些类型?::
* compile: 默认范围, 编译测试运行时都有效.
* provided: 编译和测试时都有效.
* runtime: 测试和运行时都有效.
* test: 测试时有效.
* system: 编译测试时都有效, jar包从本地读取.
* import: 当前项目里的依赖会被导入的pom替代.
Maven依赖传递的优先级是怎样的?::
* compile范围的依赖才可被传递.
* 路径最短者优先.
* 路径相同时先声明者优先.

== MyBatis

[qanda]
#{}和${}的区别是什么?::
* `\#{}` 是预编译处理, Mybatis会将sql中的 `#{}` 替换为 `?` 号，调用PreparedStatement的set方法来赋值, 参数内的引号编译后会加上转义符来防止Sql注入.
* `${}` 是纯粹的字符串替换.
当实体类中的属性名和表中的字段名不一样, 怎么办?::
* sql中使用别名, 与属性名保持一致.
* 使用 `resultMap` 来设置实体属性名和列名的映射关系.
模糊查询like语句该怎么写?::
* 属性值用 `%` 包裹.
* sql中写成 `%#{param}%`
Mapper接口里的方法可以被重载吗?::
不能, Mapper中每一个方法是用namespace加方法名作为唯一标识的.
Mybatis分页插件原理?::
. 拦截Executor query方法.
. 根据参数中的 `RowBounds` 分页参数对象, 在boundSql的sql后拼接分页查询语句.
MyBatis支持插件拦截的类?::
* ParameterHandler
* ResultSetHandler
* StatementHandler
* Executor
如何获取自增id?::
`KeyGenerator` 保存的对象中会设置自增id的值.
mapper中如何传递多个参数?::
* sql中直接用 `\#{arg0},#{arg1}...` 或者 `\#{param1},#{param2}...` 标识第几个参数.
* 方法中使用 `@Param` 注解设置参数名称, sql中使用 `#{参数名称}` 获取参数值.
* 参数使用对象或者map, sql中引用对象或者map的key.
Mybatis如何执行批处理?::
使用 `BatchExecutor` 执行批处理.
Mybatis有哪些Executor? 区别是什么?::
* SimpleExecutor: 具体实现了对数据库的操作
* ReuseExecutor: 缓存了sql的StatementHandler以重用
* BatchExecutor:
* CachingExecutor: 添加了对MappedStatement的二级缓存的读取.
Mybatis的缓存实现原理?::
* 一级缓存: `Executor` 中的 `localCache` 成员变量, 只在同一个 `sqlSession` 生命周期中有效.
* 二级缓存: `MappedStatement` 的 `cache` 成员变量, 全局共享 (为防止脏读, commit后才会缓存查询结果).
* 查询过程: 二级缓存 -> 一级缓存 -> 数据库.
Mybatis的延迟加载实现原理?::
Mybatis仅支持 `association` 关联对象和 `collection` 关联集合对象的延迟加载.
使用 `JavaAssist(默认)/cglib` 创建SQL查询结果返回对象的代理对象, 如果获取该字段值时发现是懒加载字段, 则单独发送查询关联对象的sql, 然后设置该字段的值.
Mybatis用到哪些设计模式?::
* 单例模式:
** `KeyGenerator`
* 工厂模式:
** `LogFactory`
** `TransactionFactory`
* 建造者模式:
** `CacheBuilder` 创建Cache对象.
** `ResultMapping.Builder` 创建ResultMapping对象.
** `ResultMap.Builder` 创建ResultMap对象.
** `MappedStatement.Builder`
* 装饰者模式:
** Cache实现类, 如 `ScheduledCache, LoggingCache` , 每个装饰类都在原有Cache基础上增强了功能.
* 组合模式:
** `MixedSqlNode` : 内部可以包含多个SqlNode.
* 代理模式:
** `SqlSessionManager`
** `MapperProxy`
** `ConnectionLogger`
* 模板方法模式:
** `BaseExecutor`
* 责任链模式:
** `InterceptorChain`
MyBatis的Mapper方法执行过程?::
. `SqlSessionTemplate` 使用静态代理持有 `SqlSession` 动态代理对象.
. 根据Mapper接口创建 `MapperProxy` 对象. `JDK动态代理`
. 为调用的方法创建 `MapperMethod` 对象, 并缓存到 `MapperProxy` 对象里, 执行 `MapperMethod::execute` 方法.
. 创建 `Executor` 对象(默认 `CachingExecutor` ), 从而创建 `SqlSession` , 根据方法执行 `SqlSession` 的CRUD方法.
.. 根据Mapper类名和方法名找到初始化时解析好的 `MappedStatement` .
.. 执行 `Executor` 的CRUD方法.
... 判断Mapper方法是否开启二级缓存, 如果开启则从 `MappedStatement` 里面查找缓存, 查找不到则执行 `BaseExecutor` CRUD操作然后将结果存到 `MappedStatement` 里面.
... 查找 `BaseExecutor` 的 `localCache` 一级缓存, 如果存在则直接返回, 不存在则执行sql.
... 创建 `StatementHandler` 对象预编译sql, 设置参数, 得到 `Statement` 对象.
... 使用 `ResultSetHandler` 解析sql执行的结果.
SqlSession的实现类有什么区别?::
* `DefaultSqlSession` 线程不安全, 需要手动提交/回滚/关闭.
* `SqlSessionManager` 线程安全, 可以每次创建一个 `DefaultSqlSession` 操作数据库, 也可以使用 `ThreadLocal` 复用 `SqlSession` , 支持自动提交/回滚.
* `SqlSessionTemplate` 线程安全, 将 `SqlSession` 的创建和当前session的提交/回滚/关闭交由Spring的 `TransactionSynchronizationManager` 管理.
MyBatis集成Spring后支持一级缓存吗?::
在同一个事务里支持, 否则不支持.
原因: `MyBatis` 的 `Executor` 执行commit后会清除本地的一级缓存. 如果当前查询过程是在事务中, 查询后不会自动commit, 所以不会清除缓存, 如果当前查询不处于事务中, 则会自动commit, 然后清除缓存.

== 框架

=== Spring

[qanda]
IoC含义?::
对象自身生命周期的控制以及与其他对象的依赖关系交由Spring容器管理.
依赖注入的方式?::
* 字段注入
* 构造函数注入
* setter方法注入
ApplicationContext与BeanFactory的区别?::
* BeanFactory在spring-beans包中, ApplicationContext在spring-context包中.
* ApplicationContext扩展了BeanFactory的功能:
** MessageSource: 实现国际化功能.
** EventPublisher: 实现事件订阅发布功能.
** LifeCycle: 管理生命周期.
** 集成AOP.
** 新增一些应用层context, 如 `WebApplicationContext` .
Spring自动注册Bean的方式?::
* `@Component` 注解放到类上面, 注册该类的对象到Bean容器中.
* `@Configuration` 配置类:
** `@Bean` 注解在方法上, 用来注册某一个类型的Bean.
** `@ComponentScan` 注解在配置类上, 用来扫描并注册本包以及所有子包下的带有 `@Bean/@Configuration` 的Bean.
* `@Import` 导入外部声明的 `@Configuration/@Component` 或者 `ImportSelector/ImportBeanDefinitionRegistrar` 接口的实现类来动态注册Bean.
如何手动注册Bean?::
* BeanFactory.registerBeanDefinition: 通过BeanFactory注册
* ApplicationContext.register: 通过ApplicationContext注册
* ApplicationContext.scan: 扫描包下所有的bean
单例Bean中如何注入prototype型bean?::
* `@Lookup` 一个抽象方法
* `ObjectFactory/Provider`
Bean的生命周期?::
. 创建对象:
* InstantiationAwareBeanPostProcessor::postProcessBeforeInstantiation 尝试调用一次, 如果返回不为null, 则走完 `BeanPostProcessor::postProcessBeforeInitialization` 回调就结束,详见 `AbstractAutowireCapableBeanFactory::resolveBeforeInstantiation` .
* Constructor 执行构造方法创建Bean对象, 详见 `AbstractAutowireCapableBeanFactory::createBeanInstance` .
. 注入属性和依赖
* MergedBeanDefinitionPostProcessor: 解析bean内注解信息, 详见 `AbstractAutowireCapableBeanFactory::applyMergedBeanDefinitionPostProcessors` .
* InstantiationAwareBeanPostProcessor#postProcessProperties 应用@Value注解字段对应的值, 详见 `AbstractAutowireCapableBeanFactory::populateBean` .
. 执行回调, 详见 `AbstractAutowireCapableBeanFactory::initializeBean` :
* Aware接口回调
* BeanPostProcessor::postProcessBeforeInitialization
* @PostConstruct
* InitializingBean::afterPropertiesSet
* initMethod
* BeanPostProcessor::postProcessAfterInitialization
* SmartInitializingSingleton::afterSingletonsInstantiated
. LifeCycle::start
. LifeCycle::stop
. @PreDestroy
. DisposableBean::destroy
. destroyMethod
Configuration类实例方法中直接调用该类中的方法为什么可以直接得到bean?::
Spring会为每个Configuration类生成CGLIB代理类, 代理类会拦截所有的beanMethod, 返回值为从BeanFactory中get到的bean.
什么情况下会发生Bean循环引用?::
* 两个Bean互相使用构造函数中注入, 且没有使用 `@Lazy` 懒加载.
* 两个Bean互相使用构造函数中注入, 使用 `@Lazy` 懒加载, 但在构造函数中调用了该Bean的方法触发了其初始化流程.
* 两个prototype类型的Bean互相注入, getBean的时候会报异常.
Spring如何检测Bean循环引用?::
参见 `DefaultSingletonBeanRegistry#beforeSingletonCreation` 方法.
每个Bean在创建前 `beanName` 会放到 `singletonsCurrentlyInCreation` 这个set中, Bean创建完会从这个set中移出.
解析构造函数注入或者 `@Autowired` 注解注入时会看需要注入的Bean在不在这个set中, 如果在, 则抛出循环引用异常.
Spring的三级缓存?::
* 一级缓存: `singletonObjects` : 存放已经实例化并初始化好的单例对象.
* 二级缓存: `earlySingletonObjects` : 暂存实例化好但属性没有初始化好的单例对象.(存放循环依赖下创建好但未完全初始化好的AOP对象)
* 三级缓存: `singletonFactories` : 暂存用于创建单例对象的工厂.(存放用于创建对象的工厂方法)
为什么不直接使用一级缓存?::
有循环依赖的情况下, Bean还没创建好就要暴露出去, 不方便维护, 也解决不了代理对象重复创建的问题.
为什么不使用二级缓存而是三级缓存?::
* 三级缓存保存了真正获取Bean实例的方法, 可以理解为延迟实例化, 解决AOP代理对象创建的问题, 如果不存在AOP代理对象创建的场景, 则可以不需要三级缓存.
* 当注入的是需要代理的对象时, 会从三级缓存找到该对象的实例化方法, 创建出最终的对象放到二级缓存中.
* 如果提前直接创建AOP代理对象, 直接创建好放进二级缓存, 而不使用三级缓存, 是可行的, 但违背了Spring Bean生命周期 (Aop代理对象创建的时间应该在对象初始化之后).
构造函数Bean循环引用如何解决?::
`@Autowired` 时添加 `@Lazy` 注解, 并且构造函数中不要去获取注入对象的属性/调用方法.
*原理* : 如果注入时有 `@Lazy` 注解, 则会注入一个代理, 只有当使用这个字段时才会从 `BeanFactory` 中获取真正的Bean.
为什么动态代理调用同类中方法时不走切面?::
同类方法直接调用使用的是this调用, 即被代理的原始对象, 所以在被代理的对象中直接调用同类的方法不会调用切面的代码.
如何让动态代理调用同类中方法时走切面?::
* `AopContext.currentProxy()` 显示获取当前被代理的对象, 然后调用这个对象上的方法.
* 当前Bean注入一个自己的代理对象, 这样就获取到了被代理的对象.
使用CGLIB代理有什么要求?::
CGLIB使用继承实现代理, 所以不能继承的情况下不能使用CGLIB创建代理.
* 被代理的类不能是 `final` 类.
* 被代理的方法不能是私有方法.
* 被代理的方法不能是 `static` 方法.
* 被代理的方法不能是 `final` 方法.
Spring配置的placeholder占位符是如何替换的?::
依靠 `Environment` 对象的 `propertyResolver` 解析, 替换掉 `${}` 占位符, 再从 `Environment` 的 `propertySources` 中获取该属性名对应的值.
Configuration类中@Bean方法定义成static有什么作用?::
static方法不会被代理, 所以每次调用这个方法返回的都是不同的普通对象.
AOP的Advice类型?::
* Before
* After
* AfterReturning
* AfterThrowing
* Around
@Transaction默认情况下抛出什么异常类型后会回滚事务?::
*UnChecked Exception* , 即 `RuntimeException` 及其子类或者 `Error` 异常.

=== Spring Boot

[qanda]
Spring Boot应用中为什么带有 `@SpringBootApplication` 注解的启动类要放到所有包的最外层?::
`@SpringBootApplication` 注解是 `@SpringBootConfiguration` , `@EnableAutoConfiguration` 和 `@ComponentScan` 三个注解的组合.
其中 `@ComponentScan` 注解默认扫描本包以及子包下的所有Bean, 所以默认配置下需要放到最外层的包里, 防止扫描不到其他包里的Bean.
Spring Boot的自动装配原理?::
* v2.7.0之前: `META-INF/spring.factories` 文件中添加EnableAutoConfiguration配置类名.
* v2.7.0之后: `META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports` 文件中添加AutoConfiguration配置类名.

=== Nacos

[qanda]
Nacos服务注册流程?::
. 服务启动时向NacosServer发送一个心跳包, 并调用服务注册接口将自己注册到NacosServer中, 心跳包第一次发送完之后, 会从Nacos拿到下一次发送心跳包的间隔(默认5秒), 然后循环往复持续发送.
. NacosServer收到心跳包后, 内存中存储该服务及其IP, 并更新该实例最近一次心跳时间, 如果该服务是从非健康状态变成健康状态, 则会通知其他服务.
. NacosServer启动的时候会启动一个5秒钟的定时任务, 扫描所有已注册的服务:
* 如果当前时间减去实例最近一次心跳包时间在15~30秒之间, 则会标记该实例为unhealthy状态.
* 如果当前时间减去实例最近一次心跳包时间超过30秒, 则会删除该实例.
Nacos服务发现流程?::
. 远程调用时, 会调用 `HostReactor` 获取指定服务下所有实例.
* 如果 `HostReactor` 本地存在服务实例列表, 就选择一个实例调用.
* 如果本地不存在, 则会调用Nacos接口获取所有的服务实例, 同时将本地的一个UDP端口暴露给Nacos, 如果服务有更新, Nacos通过这个UDP端口通知.
Nacos远程调用负载均衡策略?::
随机+权重: 先计算每个实例的权重占比, 然后取一个0~1的随机数, 找到权重占比比该随机数大的一个实例.
Nacos配置更新通知流程?::
. Nacos Client端向Nacos建立一个45秒的长请求, 发送自己的配置groupKey和md5.
. Nacos收到请求后判断该md5与本地的是否相同:
* 如果md5不同立即返回该groupKey, NacosClient收到后重新调用接口获取配置加载到本地, 然后发布 *refreshEvent* .
* 如果md5相同, 则创建一个长链接时间-500毫秒的延时任务, 注册一个listener, 如果配置在此期间有变动, 立即返回groupKey, 否则等到最后再返回一个空响应.
Nacos配置优先级?::
. 服务名+环境名+配置文件格式名自动生成的配置文件格式: `$\{prefix}-${spring.profile.active}.${file-extension}` .
. 一个应用可以有多个配置文件: `extensionConfig` .
. 多个服务可以共享一个配置文件: `sharedConfig` .

== Redis

[qanda]
Redis的数据类型有哪些?::
* string
* list
* set
* hash
* zset
* bitmap
* geo
* stream
* hyperLogLog
Redis各个数据类型的编码方式有哪些?::
* string
** `int`
*** 条件: 存储的是数字, 范围为stem:[-2^63~2^63-1] , 如果数字为0~10000, 使用共享对象.
*** 如果存储的数字大于 stem:[2^63-1] , 则转为 `raw` 存储.
** `embstr` : 字符串长度小于等于44个字节.
*** 字符串和key所属的RedisObject对象连续存储, 分配和删除时只需操作一次内存, 所以 `embstr` 被设计成只读的.
*** 如果使用了 `append` 命令修改字符串, 则会变成使用 `raw` 存储.
** `raw` :
*** 条件: 字符串长度大于44个字节.
*** 字符串和key所属的RedisObject对象分开存储.
* list
** `ziplist`
*** 条件: 列表元素数量小于512个(list-max-ziplist-entries)并且每个元素长度小于64字节(list-max-ziplist-value)的情况下使用 `ziplist` 存储.
** `linkedlist`
* hash
** `ziplist` : field和value依次存储.
*** 条件: 列表元素数量小于512个(set-max-intset-entries)并且每个元素长度小于64字节的情况下使用 `ziplist` 存储.
** `hashtable`
* set
** `intset` : 使用整数集合作为底层实现.
*** 条件: 集合中所有元素都是整数且元素数量不超过512个(set-max-intset-entries).
** `hashtable`
*** 哈希表中每个节点key为set中元素, value为null.
* zset
** `ziplist` : value和score存储, 并按照score从小到大排序.
*** 条件: 保存的数量小于128个(zset-max-ziplist-entries)并且每个元素长度小于64个字节(zset-max-ziplist-value).
** `skiplist`
如何查看key的编码方式?::
`object encoding <KEY>` .
Redis对象怎么存储的?::
* type: 4位, 标识对象的类型.
* encoding: 4位, 标识对象的编码方式.
* lru: 24位, 高16位标识对象被访问的时间, 低8位标识对象被访问的次数.
* refcount: 4字节, 对象被引用的次数.
* *ptr: 8字节, 指向具体存储数据的指针.
SDS对象怎么存储的?::
* len: 标识字符串实际长度.
* free: 标识字符数组空余长度.
* buf[]: 用于保存字符串数据的字符数组.长度: `len+free+1` .
一个string类型的值能存储最大容量是多少?::
512MB.
Redis的String类型使用SDS方式实现的好处?::
* 使用len存储字符串长度, 提高性能.(C语言获取字符串长度时间复杂度为O(n))
缓存的更新策略有几种? 分别有什么注意事项?::
* 先删缓存, 再更新数据库 (更新数据库期间会存在读旧数据写到缓存的情况).
* 先更新数据库, 再删缓存.
* 如果数据库存在主从同步延迟的情况, 先更新数据库, 再同步删缓存(清除旧数据, 如果清完缓存但DB从库里还没同步完成, 会读到旧数据), 最后延迟2秒再删一次缓存(保障缓存数据最新).
如何设置Redis的内存上限? 有什么作用?::
`maxmemory` 配置项,
Redis的淘汰策略有哪些?::
* `noeviction` (默认) 禁止淘汰数据.
* `volatile-lru` (设置了 `maxmemory` 下的默认配置): 从已经设置过期时间的数据集中, 挑选最久未使用的数据淘汰.
* `volatile-lfu` (设置了 `maxmemory` 下的默认配置): 从已经设置过期时间的数据集中, 挑选最少使用的数据淘汰.
* `volatile-ttl`  从已经设置过期时间的数据集中，挑选即将要过期的数据淘汰.
* `volatile-random` 从已经设置过期时间的数据集中，随机挑选数据淘汰.
* `allkeys-lru` 从所有的数据集中, 挑选最久未使用的数据淘汰.
* `allkeys-lfu` 从所有的数据集中, 挑选最少使用的数据淘汰.
* `allkeys-random` 从所有的数据集中, 随机挑选数据淘汰.
Redis过期键的删除策略？::
Redis使用惰性删除+定期删除的策略来删除过期key.
* 惰性删除：放任过期键不管，但是每次从键空间中获取键时，都检查取到的键是否过去，如果过期就删除，如果没过期就返回该键。（被动删除） 对cpu时间友好，程序只会在取出键的时候才会对键进行过期检查，这不会在删除其他无关过期键上花费任何cpu时间，但是如果一个键已经过期，而这个键又保留在数据库中，那么只要这个过期键不被删除，他所占用的内存就不会释放，对内存不友好。
* 定期删除：每隔一段时间就对数据库进行一次检查，删除里面的过期键。（主动删除） 采用对内存和cpu时间折中的方法，每个一段时间执行一次删除过期键操作，并通过限制操作执行的时长和频率来减少对cpu时间的影响。难点在于，选择一个好的策略来设置删除操作的时长和执行频率。
* 定时删除：在设置键的过期时间的同时，创建一个timer，让定时器在键的过期时间到达时，立即执行对键的删除操作。（主动删除） 对内存友好，但是对cpu时间不友好，有较多过期键的而情况下，删除过期键会占用相当一部分cpu时间。
设计下用户签到功能?::
设置两个bitmap, 一个维护单个用户的签到数据, 一个维护指定日期的签到用户数据.
* `setbit punch:user:1001 20211112 1` : 用户1001在2021-11-12日签到, 这样可以统计出该用户历史的签到数据.
* `setbit punch:date:20211112 1001 1` : 统计每日用户签到用户明细. (单统计人数也可用hash)
Redis的请求响应模式有哪些?::
* ping-pong
* pipeline
如何解决Redis的并发竞争Key的问题?::
watch
Redis持久化机制有哪些? 区别是什么?::
* rdb: 将内存快照全量写入到rdb文件里.
** 配置方式: `save <SECONDS> <COMMAND_NUMS>` 每m秒至少有n个命令执行后会自动bgsave一次.
** 优点: RDB是二进制压缩文件, 占用空间小, 便于传输.
** 缺点: 数据存储存在延时性, 最后一次内存快照dump之后的数据在RDB文件里是没有的.
* aof: 将执行的增删改命令增量写入到文件里.
** 配置方式: `appendonly yes, appendfsync everysec` 每秒fork一个子进程刷新一次aof缓冲区内容到文件中.
** 优点: `everysec` 顶多丢失1秒种数据, `always` 不会丢数据, 数据安全性比rdb高.
** 缺点: 占用空间大, 恢复数据没有rdb快.
什么时候触发写RDB?::
* 根据RDB规则定时写.
* 执行 `save` 或者 `bgsave` 命令.
* 执行 `flushall` 命令.
* 第一次执行主从复制操作.
`bgsave` 的执行过程?::
. Redis父进程首先判断, 如果当前正在执行save/bgsave/bgrewriteaof, 则立即返回.
. Redis父进程fork出一个子进程(会阻塞), 然后立即返回.
. 子进程创建RDB临时文件, 然后替换原有文件.
. 子进程发送信号给父进程, 父进程更新统计信息.
`appendfsync` 选项含义?::
* `no` : Redis不主动将AOF缓冲区内容写入到文件里, 完全依赖操作系统.
* `always` : 每个写命令都会同步将AOF缓冲区内容写入到文件里.
* `everysec` : 每秒执行一次磁盘同步.
如果同时开启rdb和aof, Redis重启后会用哪种方式恢复数据?::
同时开启rdb和aof时, 会生成rdb和aof文件, Redis重启后会先加载rdb文件到内存, 然后重放aof文件中的命令.
如果AOF文件的数据出现异常, 怎么处理?::
Redis重启失败, 需要使用 `redis-check-aof --fix <AOF_FILE>` 来修复AOF文件.
Redis通讯协议是什么? 有什么特点?::
`RESP`.
描述下Redis的线程模型?::
Reactor线程模型.
Redis事务相关命令有哪些?::
* `multi` : 标记开启一个事务命令队列.
* `exec` : 执行整个事务里的命令.
* `discard` : 清除事务里的命令.
* `watch` : 监视某个key.
* `unwatch` : 取消当前 `watch` 操作.
Redis事务支持原子性吗?::
在一定情况下不支持.
* multi命令队列里, 如果出现存在某一个命令语法错误, 则统一不会执行.
* 如果不存在语法错误但运行时报错, 则报错命令之前的正确命令会执行成功且不会回滚.
Redis如何执行lua脚本?::
. 使用 `eval` 命令: `eval "<SCRIPT>" <NUMBER_OF_KEYS> KEY1 KEY2 ARG1 ARG2 ...` , 如 `eval "return {KEYS[1], KEYS[2], ARGV[1]}" 2 k1 k2 a1`
* lua脚本中可以执行Redis命令:
** `redis.call` : 如果出错, 后面的脚本不会执行.
** `redis.pcall` : 如果出错, 后面的脚本继续执行.
. 使用 `evalsha` 命令:
.. 先使用 `scriptload` 命令发送给Redis, 返回SHA1摘要.
.. 使用 `evalsha` 命令执行预先加载的lua脚本: `evlasha <SHA1_HASH> <NUMBER_OF_KEYS> KEY1 KEY2 ARG1 ARG2 ...` .
请说明一下Redis的multi命令与Pipeline有什么不同?::
* 出发点不同: multi命令是为了多个命令的原子性, pipeline是为了减少网络连接次数, 减少Redis请求压力.
* Pipeline是在客户端缓冲命令, 然后打包发给Redis, Redis再一次性返回命令执行结果, multi执行中每个命令都会发给Redis, 在Redis服务端缓冲命令.
* Pipeline每个命令都是独立执行的, multi如果出现存在某一个命令语法错误, 则统一不会执行.
请说明一下Redis的multi命令与lua脚本有什么不同?::
* multi每个命令执行期间, 其他的命令可以插队执行.
* lua脚本执行期间, 其他命令需要排队执行.
Redis慢查询是什么? 通过什么配置?::
Redis使用列表记录查询超过一定时间的命令日志:
* `slowlog-log-slower-than 1000` : 执行时间超过多少微秒的命令会被记录到日志, 小于0则配置为不记录日志.
* `slowlog-max-len 128` : 存储慢查询日志条数.
Redis记录的慢查询日志格式是什么样的?::
* 命令ID.
* 命令执行的UNIX时间戳.
* 命令执行花费的时长, 单位微秒.
* 执行的命令及参数.
* 客户端IP及端口.
什么是缓存穿透? 怎么解决?::
缓存穿透指查询数据库不存在的数据, 从而每次请求都会查询DB, 导致DB负载变大.
* 查不到的数据也缓存null值.
* 使用布隆过滤器维护所有id列表, 查询时先查询id是否存在, 如果不存在就直接返回, 否则再继续查询缓存和DB.
什么是缓存雪崩? 怎么解决?::
缓存雪崩指大量key同一时间失效, 导致都请求到DB上.
* 给缓存key设置失效时间时加上随机值.
* 增加二级缓存, 如失效时间很短的JVM本地缓存.
* 读取时增加互斥锁.
什么是缓存击穿? 怎么解决?::
缓存击穿指某个热点key在失效的那一刻有大量请求同时到来, 查询DB, 导致DB负载变大.
* 对接口增加限流.
* 读取时增加互斥锁.
Redis集群架构模式有哪几种?::
* 主从复制
* 哨兵模式
* 集群分区模式
Redis集群的主从复制模型是怎样的?::
. 从节点设置主节点的ip, 端口和密码.
. 从节点建立主节点的socket连接, 发送密码进行认证.
. 从节点不知道主节点的runId, 发送 `psync ? -1` 命令表示第一次同步.
. 主节点执行 `bgsave` , 生成rdb文件, 发送给从节点, 全量同步期间的命令会写入一个缓冲区, 等全量同步完成后继续发送给从节点.
* 这一步主节点返回 `fullresync <runId> <offset>`
* runId代表主节点的uuid, offset标识同步数据的偏移量.
. 从节点加载rdb文件, 保存到自己数据库中.
. 随后主节点进行增量复制, 从节点收到命令后执行, 并每秒向主节点汇报自己的offset.
. 从节点重启后, 会发送本地的offset, 主节点首先从发送过的命令缓冲区中查找, 如果存在, 则将该offset位置后的命令进行增量同步, 否则全量同步.
. 主节点可以配置从节点的健康阈值, 如果超过阈值则主节点变成只读状态.
* `min-replicas-to-write 3` : 如果健康的从节点小于3个, 则Redis主节点变为只读状态.
* `min-replicas-max-lag 10` : 如果从节点延迟超过10秒, 则被标记为不健康状态.
Redis集群的主从复制模式有什么优缺点?::
* 优点:
** 同步备份数据, 保障Redis高可用.
** 可进行读写分离, 减少主库请求压力, 提升性能.
** Redis从库快速重启后, 也能进行增量同步.
* 缺点
** 主从切换后, 客户端也需要变更连接的Redis地址.
Redis哨兵的监控机制是怎样的?::
. 每个Sentinel每秒一次向它所知的主/从/Sentinel节点发送一个 `PING` 命令.
. 如果一个实例（instance）距离最后一次有效回复 `PING` 命令的时间超过 down-after-milliseconds 选项所指定的值, 则这个实例会被 Sentinel 标记为主观下线.
. 当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态, 则Master会被标记为客观下线.
. 若没有足够数量的 Sentinel 同意 Master 已经下线, Master 的客观下线状态就会被移除.
若 Master 重新向 Sentinel 的 PING 命令返回有效回复, Master 的主观下线状态就会被移除.
. 所有的Sentinel节点会通过raft算法选出一个 `Leader` 节点, `Leader` 节点选择一个从节点替代原有的Master节点, 并修改旧的master节点的配置文件为replicaof新的Master节点.
主节点宕机后, Redis哨兵模式下按照什么优先级选拔从节点作为新的主节点?::
. 首先比较 `replica-priority` 属性, 如果都没配则继续比较, 否则最高的节点为准.
. 比较偏移量, 如果都相同则继续比较, 否则以偏移量最高的节点为准.
. 比较runId, 以最小的节点为准, 因为runId越小表示重启次数越少.
Redis的哨兵模式优缺点有哪些?::
* 优点:
** master宕机后, 能够及时监控到, 自动故障转移切换从库, 无需人工干预.
* 缺点:
** 增加系统复杂度, 需要额外的机器资源.
Redis的集群模式优缺点有哪些?::
* 优点:
** 可以充分利用多个机器的资源, 提升性能.
** Redis集群模式也支持自动故障转移, 来实现集群高可用.
* 缺点:
** 涉及多个key的命令可能会因为分散在不同的分区上而执行失败, 如对两个set求交集.
Redis集群模式下一致性哈希相比较普通的哈希算法有什么优势?::
* 普通哈希下如果节点数量变更, 所有的key都要重新计算槽位, 而一致性哈希下, 只有一部分数据需要做迁移.
Redis集群最大节点个数是多少?::
16384个.
Redis集群会有写操作丢失吗? 为什么?::
Redis集群属于AP模型, 主从同步存在延时, 但是可以保证最终一致性.
如果某个主从节点全部宕机, 那么会出现写操作丢失.
如何查看Redis的当前连接数?::
执行命令 `info clients` , 查看 `connected_clients` 项.
如何设置Redis的最大连接数?::
`maxclients 10000` 配置项, 默认为10000.
如何查看Redis的最大连接数?::
执行命令 `config get maxclients` .
Redis如何做内存优化?::
* 避免写入大key, 分散为小的key.
* key长度尽量短.
* 缓存数据设置超时时间, 减少内存资源浪费.
* 避免使用 `keys/hgetall` 等全量命令.
* 如果Redis单纯用作缓存数据库, 可以关闭持久化或者用aof.
* 执行多个命令时, 可以使用pipeline打包.
* Redis独立部署, 防止内存不足而使用swap分区.
什么是 bigkey? 有什么影响?::
bigkey指存储的值非常大的key.
* 因为Redis使用单线程接收请求, 传输bigkey会降低Redis的吞吐量.
* bigkey会造成主从同步延迟上升.
* 删除bigkey时可能会因为操作时间长而阻塞客户端.
如何发现Redis里的bigkey?::
* 使用 `redis-cli --bigkeys` 命令.
* 使用第三方工具(如 `redis-rdb-tools` )分析rdb文件.
请介绍几个可能导致Redis阻塞的原因?::
* 执行 `save` 命令.
* 读写bigkey.
* fork子进程发生阻塞.
* 如果配置了 `appendfsync always` 且磁盘饱和度比较高, 则刷新缓冲区内容到文件耗时会比较长.
怎么去发现Redis阻塞异常情况?::
* 执行 `slowlog get` 查看近期的慢查询日志.
* 查看机器内存是否充足, 如果系统使用了swap分区, 则会严重影响Redis性能.
* 使用 `info stats` 命令查看 `lastest_fork_usec` 最近一次fork子进程耗时, 如果Redis数据量过多, fork耗时会比较长.
设计一下在交易网站首页展示当天最热门售卖商品的前五十名商品列表?::
zset

== Database

[qanda]
`count(*)` 和 `count(列名)` 有什么区别?::
`count(列名)` 会过滤掉null行, `count(*)` 不会
b树和b+树的区别?::
* B+树的非叶子节点不存储数据, 只存储索引, 这样每一层可以存放更多的索引, 减少磁盘随机IO次数.
* B+树的叶子节点包含索引值或索引所在行的数据.
* B+树的叶子节点有指针指向左右两边的叶子节点.(MySQL中页为双向指针, 页里的数据记录为单向指针)
b+树索引和hash索引的区别?::
* hash索引不支持排序.
* hash索引不支持范围查询.
* hash索引不适用最左匹配原则.
如何更好地创建索引?::
* 为出现在where/order by/group by的列创建索引.
* 如果列重复数据比例较高, 则可能没有创建索引的必要.
* 索引列的数据类型尽量短小.
* 查询时尽量覆盖索引, 避免回表.
* 聚集索引中主键应尽量按插入顺序排序(如主键自增), 避免插入时移动页数据, 增大插入开销.
* 如果存在联合索引, 则没有必要再去为第一列创建一个普通索引, 避免重复.
事务的ACID特性?::
* 原子性: 一个事务是一个不可分割的单位, 操作要么全部成功, 要么全部失败.
* 一致性: 事务执行前后数据在语义上处于合法的状态.
* 隔离性: 多个事务并发操作时不能相互干扰.
* 持久性: 事务一旦提交, 对数据库的改变应该是永久性的.
事务并发执行的问题?::
* 脏写: 一个事务修改了另外一个事务未提交的数据.
* 脏读: 一个事务读取了另外一个事务未提交的数据.
* 不可重复读: 一个事务先后读取了另外一个update事务提交的数据, 两次读取数据不一致.
* 幻读: 一个事务先后读取了另外一个insert/delete事务提交的数据, 两次读取数据量不一致.
事务的隔离级别?::
* read uncommitted: 解决脏写.
* read committed: 解决脏读.
* repeatable read: 解决不可重复读.
* serializable: 解决幻读.
分区和分表的区别?::
* 分表分为水平分表和垂直分表: 水平分表指将表中的多行数据按照规则分到不同的表中存储, 垂直分表指将表中的多列数据按照规则分到不同的表中存储.
* 分区是水平分表的实现方式, 可以通过range/hash/list等规则划分分区, 或者通过父子表+check约束实现.
* 分区无法保证

=== MySQL

[qanda]
MySQL `Innodb` 和 `MyIsam` 引擎的区别?::
* MyIsam使用堆表保存索引和数据, InnoDB使用索引组织表保存索引和数据.
** 堆表: 聚集索引和数据分开存储, 索引存放数据文件的pageID和tupleID.
** 索引组织表: 非聚集索引的叶子节点存储主键和pageID, 聚集索引的叶子节点直接存储数据.
* MyIsam不支持事务和行级锁, InnoDB支持.
MySQL的page大小是多少?::
16kb
MySQL有哪些索引?::
* 主键索引
* b+树索引: create index on table(column)
* 唯一索引: create unique index on table(column)
* 哈希索引: create index on table(column) using hash
* 全文索引: create fulltext index on table(column)
* 地理位置索引: create spatial index on table(column)
* 前缀索引: create index on table(text/blob_column(length))
MySQL执行计划中type类型有哪些?::
* const: 主键或唯一索引查询, IS NULL查询除外.
* ref: 普通二级索引等值查询.
* ref_or_null: 普通二级索引等值 `OR IS NULL` 查询.
* eq_ref: 两个表的唯一索引列JOIN关联查询.
* range: 索引范围查询.
* index: 二级索引查询(不回表)或者排序.
* index_merge: 使用了多个不同索引列查询.
* all: 全表扫描.
* fulltext: 全文索引查询.
MySQL执行计划中extra类型有哪些?::
* No table used: 查询语句没有from表.
* Impossible WHERE: where语句永远为false.
* No matching min/max row: 查询列有min/max函数但是没有查询结果.
* Using index: 使用到覆盖索引.
* Using index condition: 使用到二级索引下推判断where条件是否符合.
* Using where: 在内存中判断where条件是否符合.
* Using join buffer (Block Nested Loop): 使用join buffer来筛选被驱动表数据, 减少对被驱动表的访问次数.
* Using intersect: 使用多个索引合并的方式查询.
* Zero limit: 查询语句存在limit 0.
* Using filesort: 在内存或者磁盘中对数据进行排序.
* Using temporary: 使用到临时表.
MySQL binlog日志格式?::
* statement: 记录执行的SQL语句.
* row: 记录SQL执行后被修改的行数据.
* mixed: 根据执行的SQL动态选择statement或者row格式.
MySQL默认的事务隔离级别?::
Repeatable Read
MySQL如何保证事务ACID特性?::
* 原子性: undo log.
* 隔离性: 锁+MVCC.
* 持久性: redo log.
* 一致性: 前三个特性保证了, 一致性也就保证了.
MySQL redo日志的作用?::
为了保证持久性, 在SQL执行过程中会把对数据库表空间下所有页的修改记录下来, 以便在数据库崩溃重启后恢复.
MySQL redo日志的lsn?::
* lsn: 表示系统写入redo日志的总量(字节数).
* flush_to_disk_lsn: redo日志buffer中完成刷盘的lsn.
* checkpoint_lsn: 表示当前系统中已经刷完盘可以被覆盖的redo日志总量.
MySQL redo日志恢复的过程?::
. 找到最后一次刷盘的checkpoint_lsn, 此lsn为redo日志恢复的起点, 日志中lsn小于checkpoint_lsn的说明已经刷完盘, 不需要恢复.
. 日志block header中 `LOG_BLOCK_HDR_DATA_LEN` 小于512的说明该block为最后一个没写完的block, 此block为日志恢复的终点.
. 过滤掉待恢复的页header中 `FILE_PAGE_LSN` 大于checkpoint_point的页, 该页说明在checkpoint后已经刷完盘过, 不需要恢复.
. 将待恢复的日志按表空间id+pagenumber为key组成哈希表(拉链法), 按页恢复数据.
. 通过undo日志找到系统崩溃前活跃的事务id, 回滚事务.
MySQL undo日志的作用?::
为了保证原子性, 记录事务过程中增删改操作对应的回滚操作, 以便事务回滚.
MySQL undo日志的类型?::
* TRX_UNDO_INSERT_REC: 对应insert操作的undo日志, 记录主键值.
* TRX_UNDO_DEL_MARK_REC: 对应delete操作的undo日志, 记录主键值和索引列值.
* TRX_UNDO_UPD_EXIST_REC: 对应update原地更新操作的undo日志, 记录主键值和被更新的列值和被更新的索引列值.
MySQL开启事务的方式?::
* `BEGIN`
* `START TRANSACTION`
MySQL MVCC实现原理?::
. MySQL针对每行数据存在两个隐藏列: trx_id(当前操作该行记录的事务id)和roll_pointer(该行对应的undo日志指针). undo日志也存在之前行对应的上一个roll_pointer, 所以每行数据可以根据roll_pointer从undo日志中组成一个版本链.
. 事务中每次(Read Committed)或者第一次(Repeatable Read)select查询时, 会生成一个ReadView, 包含四个属性:
* m_ids: 当前未提交的事务id列表.
* min_trx_id: 当前最小的未提交事务id.
* max_trx_id: 下一个事务id.
* creator_trx_id: 当前创建ReadView的事务id.
. select读取数据时, 会遍历版本链中事务id:
.. 如果该版本的事务id等于creator_trx_id, 则该版本可见.
.. 如果该版本的事务id小于min_trx_id, 则说明该事务已提交, 该版本可见.
.. 如果该版本的事务id大于等于max_trx_id, 则说明该事务属于当前事务之后开启的事务, 该版本不可见.
.. 如果该版本的事务id在m_ids中, 说明该事务未提交, 该版本不可见; 如果不在, 说明该事务在生成ReadView时已提交, 该版本可见.
. 如果select不是全表扫描, 而是查询的二级索引数据, 则判断当前ReadView的min_trx_id是否大于二级索引页的最大事务id, 如果大于则说明事务已提交, 该二级索引页数据可见, 否则回表根据聚簇索引行数据隐藏列再去判断.
. MySQL的Repeatable Read级别由于只是在第一次生成ReadView, 可以一定程度上解决幻读. 但是如果当前事务中更新了其他事务插入的数据, 那么该数据的事务id会变成当前事务id, 那么该数据会对当前事务可见.
MySQL的锁有哪些?::
* 根据锁的属性分类:
** 共享锁: 读读不互斥, 读写/写写互斥.
** 排他锁: 读读/读写/写写互斥.
* 根据锁的粒度分类:
** 表锁: 锁住整个表记录.
*** 意向锁: 当对某行加S/X锁时, 会对表加IS/IX锁.
*** AUTO-INC锁: 插入数据时需加锁计算自增列数值, 插入完成后释放锁, 无需等待事务结束.
** 行锁: 锁住一到多行记录, 包含记录锁/间隙锁/临键锁.
** 记录锁: 锁住单行记录, 防止脏读.
** 间隙锁: 锁住索引区间.
** 临键锁: 记录锁+间隙锁的组合, 锁住查询条件范围和下一个相邻的区间.加了临键锁后, 范围内不能更新和插入.
** 插入意向锁: 如果插入记录的位置被别的事务加了间隙锁, 则会生成一个插入意向锁等待.
** 隐式锁
* 根据锁的状态分类:
** 意向共享锁
** 意向排他锁
+
.RR隔离级别下加锁判定
|===
| 查询类型 | 唯一索引 | 非唯一索引

| 等值查询
a|
记录存在 -> 记录锁;
记录不存在 -> 间隙锁
a| 记录存在 -> 临键锁+间隙锁;
记录不存在 -> 间隙锁

| 范围查询
| 左区间的临键锁/记录锁 + 右区间的临键锁/间隙锁
| 左区间的临键锁 + 右区间的临键锁

|===
+
MySQL表中的隐藏列有哪些?::
* DB_ROW_ID: 每行的唯一标识id, 如果表中没有主键和唯一键, 则会生成row_id.
* DB_TRX_ID: 事务id.
* DB_ROLL_PTR: 回滚指针.
MySQL统计表中数据量的方式?::
* count(*)
* `select * from mysql.innodb_table_stats where database_name = '数据库名' and table_name = '表名';` n_rows列(估算值)
* `show table status like '表名';` Rows列(估算值)
* `select * from information_schema.tables where TABLE_SCHEMA = '数据库名' and TABLE_NAME = '表名';` TABLE_ROWS列(估算值)
MySQL分区的方式?::
* range
* list
* hash: 支持表达式
* key: 不支持表达式, 使用MD5计算hash.
* 复合分区: 对一列多次分区, 如range+hash.

=== PostgreSQL

[qanda]
PostgreSQL中scan类型有哪些?::
* Seq Scan: 顺序扫描表所有数据.
** 查询条件没有命中索引
* Index Scan: 先扫描索引页, 找到符合条件的索引元组, 根据索引元组里的 `ctid` 从堆表中取行数据.
** 查询条件命中索引
** 需要回表
* Index Only Scan: 扫描索引页, 筛选然后直接从索引元组取数据.
** 查询条件命中索引
** 不需要回表
* Bitmap Scan: 根据查询条件将索引页一次性全部取出, 并在内存中排序, 再根据 `ctid` 回表取行数据.
** 查询条件命中索引
** 需要回表
** 属于范围查询
PostgreSQL的索引类型有哪些?::
* b+树
* hash
* gin: 倒排索引, 用于数组查询或者全文搜索
* brin: 稀疏索引
* gist: 多叉树索引, 用于范围查询
* sp-gist: 空间索引, 用于geo/ip查询.
* pg_tgrm: 全文索引
PostgreSQL的gin和gist索引有什么区别?::
* gist索引是有误差的, gin索引是准确的.
* gin的查询性能比gist高, 但是插入/更新/存储成本比gist高, 所以静态数据+准确性要求高选gin.
* gist可以自定义扩展操作符, gin固定内置操作符.
PostgreSQL的窗口函数有哪些?::
* row_number(): 为每个分组内的行分配一个唯一的顺序号, 序号从1开始.
* rank(): 为每个分组内的行分配一个顺序号,如果有相同值则分配相同的序号,序号不连续.
* dense_rank(): 为每个分组内的行分配一个顺序号,如果有相同值则分配相同的序号,序号连续.
* percent_rank(): 计算当前行处于所有行顺序的百分比, 计算结果为(相对位置-1)/(总行数-1), 返回值为[0,1], 如果有重复行按第一行的位置.
* cume_dist(): 计算当前行+之前所有行的累计分布, 计算结果为相对位置/总行数, 返回值为(0,1], 如果有重复行按最后一行的位置.
* ntile(n): 将分组内的行平均分为n个组, 为每行按顺序分配1到n之间的组号.
* sum(): 从第一行累加到当前行.
* avg()
* max()
* min()
* lag(column[, offset[, default_value]]): 返回当前行前第offset行的值,如果不存在则返回default_value.
* lead(column[, offset[, default_value]]): 返回当前行后第offset行的值,如果不存在则返回default_value.
* first_value(column): 返回分组内第一个值.
* last_value(column): 返回分组内最后一个值.
* nth_value(column, n): 返回分组内第n个值.

=== Elasticsearch

[qanda]
ES的应用场景?::
* 全文搜索
* 日志分析
* 聚合报表
ES集群节点的角色有哪些?::
* master: 负责处理集群节点管理, 索引配置, 索引分片分配, 选举等.
* coordinating: 负责接收客户端请求和返回结果, 设置方式: `node.roles: []`
* voting_only: 负责master选举.
* data: 负责CRUD索引数据.
* ingest: 负责在数据索引前执行前置操作.
* data_content
* data_hot
* data_warm
* data_cold
* data_frozen
* ml: 机器学习节点.
* remote_cluster_client: 负责连接远程的ES集群处理.
* transform
ES查询文档的处理流程?::
* 根据文档id查询:
. 客户端发送请求到coordinating节点.
. coordinating节点根据_id转发请求到文档所在分片的node, 主分片和副本分片随机选择.
. node返回文档数据到coordinating节点, coordinating节点返回给客户端.
* 条件查询:
. 客户端发送请求到coordinating节点.
. coordinating节点转发查询请求到该索引所有分片所在的node.
. node返回文档_id到coordinating节点.
. coordinating节点根据文档_id转发到所在分片的node.
. node返回文档数据到coordinating节点, coordinating节点排好序返回给客户端.
ES的字段数据类型有哪些?::
* 普通数据类型: binary, boolean, long, double, keyword, constant_keyword, wildcard, date, date_nanos, alias
* 对象数据类型: object, flattened, nested, join
* 结构化数据类型: long_range, double_range, date_range, ip_range, ip, version, murmur3
* 聚合数据类型: aggregate_metric_double, histogram
* 全文搜索类型: text, completion, token_count, search_as_you_type
* 文档排行类型: dense_vector, sparse_vector, rank_feature, rank_features
* 空间数据类型: point, geo_point, shape, geo_shape
ES字段类型text和keyword的区别?::
* text和keyword都支持精确查询和模糊查询.
* text支持分词查询, keyword不支持.
* text不支持聚合查询, keyword支持.
ES查询search_type有哪些类型?::
* query_then_fetch: 向索引所有分片查询, 各个分片返回符合的文档_id和score, 然后再根据score排好序, 筛选size数量的文档, 最后根据筛选出来的_id取文档数据.
* dfs_query_then_fetch: 查询索引所有分片的TF和DF值, 汇总后代入查询请求中再次进行query_then_fetch.
ES如何保证读写一致性?::
* 写: `wait_for_active_shards` 参数控制写完多少分片后请求才会返回, 默认写完主分片返回.
* 读: `_preference=primary` 参数控制读主分片上的数据.
* 更新: 更新时可以指定 `_version` 字段, 如果不是最新的版本则更新失败.
ES分页查询的方式?::
* from+size
* search_after
* scroll
ES索引refresh和flush的区别?::
* refresh: 将内存buffer中的数据写入到segment中, 并同步给副本分片.
* flush: 将translog中的数据持久化到硬盘.

== 消息队列

=== MQ

[qanda]
消息队列的作用?::
* 解耦
* 异步
* 削峰
* 性能: 并发批量处理提高吞吐量.
消息队列的缺点?::
* 系统可用性降低: 一旦消息队列宕机, 生产者消费者都会受到影响.
* 系统复杂度提高: 需要关注消息是否会丢失/消息是否会重复消费/消息顺序性能否保证等问题.
* 数据一致性问题: 消费者消费失败如何解决.
消息队列如何选型?::
* Kafka:
** 优点: 吞吐量大性能高.
** 缺点: 消息会丢失, 功能单一, 不支持条件过滤/死信/延迟消息等功能.
** 适用场景: 日志记录, 大数据传输.
* RabbitMQ:
** 优点: 消息可靠性高, 功能全面.
** 缺点: 吞吐量低, erlang语言开发难以定制.
** 适用场景: 小规模场景.
* RocketMQ:
** 优点: 高吞吐量, 高可用, 功能全面.
** 缺点: 客户端只支持Java.
** 适用场景: 兼顾性能和功能的通用场景.


=== RocketMQ

[qanda]
为什么自动创建的topic只会在一个broker上创建, 且只有4个队列?::
当Producer查询TBW路由信息时会设置队列数为min(TBW默认队列数8, Producer默认自动创建队列数4)=4, 然后向一个Broker发送消息, Broker收到消息后新建Topic路由, 并上报给NameServer, 下一次Producer定时拉取NameServer配置时就会同步更新这个只有一个Broker的Topic路由信息.
如果消息发送很多很快时会发送给所有的Broker, 则NameServer上收到所有的Broker上报路由信息.
如何将消息发送至指定的MessageQueue?::
实现MessageSelector接口, 生产者使用 `send` 发送消息时传第二个参数.
RocketMQ故障延迟机制?::
* 如果未启用故障延迟机制, 则只会在发送消息失败重试时会规避上一次失败的Broker.
* 如果启用了故障延迟机制, 则会根据发送latency在一定时间内一直规避上一次失败的Broker.
什么情况下会导致消息重复消费?::
* 消费者提交offset前宕机.
* 消费过程中 `rebalance` , 消费中的queue被分配给其他消费者, 则此刻未提交的消息会被其他消费者消费一次.
RocketMQ如何保证消息不丢失?::
* 消息发送: 消息可以选择同步发送, 发送异常后重试(默认最多重试3次).
* 主从同步: 消息发送到master broker后会等待消息同步给所有slave节点(默认最多等待10s).
* 消息存储: 同步刷盘: 消息提交到内存后立即刷新到硬盘.
* 消息消费: 消费完成后手动提交offset.
RocketMQ的刷盘策略?::
* 同步刷盘: Broker收到消息后, 写入内存再提交刷盘任务, 将待提交的数据(write到flush指针范围)批量写到硬盘再返回.
* 异步刷盘: Broker收到消息后, 写入内存后直接返回, 另起一个500ms的定时线程将 `pagecache` 写入硬盘.
RocketMQ如何提高消息写入性能?::
* `commitlog` 文件会mmap映射到JVM内存, 写入消息时先写内存再由Broker配置决定同步刷盘还是异步刷盘.
* master节点同步消息到slave节点时, 使用CompletableFuture异步批量发送然后等待完成.
. 如果开启transientStorePoolEnable, 则先写到堆外内存, 避免受到GC影响, 然后异步刷到mmap出来的JVM内存, 最后异步刷盘.
RocketMQ事务消息实现原理?::
. Producer发送一个half消息, 暂存到Broker中.
. Producer执行本地事务回调: `TransactionListener#executeLocalTransaction` .
. Producer发送commit或者rollback状态或者到Broker, Broker将消息恢复到用户原先发送的Topic中供消费者消费.
. 如果Producer发送的是UNKOWN状态或者未发送, 则Broker会回调 `TransactionListener#checkLocalTransaction` 方法检查状态, 根据结果重复步骤3/4, 默认最多重复15次, 超过则丢弃消息.
. 如果消费者消费失败则消息会重新进入队列消息, 默认重试超过16次后还是失败则会进入死信队列让人工干预.
push和pull消费模式区别?::
* pull: 消费客户端手动调用pull拉取消息, 消费完手动提交offset.
* push: 消费客户端注册消息消费的回调. 消费完会自动提交offset并拉取下一批消息继续消费.
RocketMQ如何实现消息顺序消费?::
* 对于同一主体的消息可以根据业务id发送到相同的MessageQueue, RocketMQ保证同一个MessageQueue内消息有序.
* Broker针对顺序消息存储和消费时会对MessageQueue加同步锁.
* 消费者单线程消费且加同步锁, 并处理消息消费时的异常, 如果不处理异常则RocketMQ会一直重试这条消息并不会消费下一条.
RocketMQ消费者队列分配策略?::
* AllocateMessageQueueAveragely(默认): 平均分配, m个队列,n个消费者, 按队列顺序为每个消费者平均划分m/n个队列.
* AllocateMessageQueueAveragelyByCircle: 环形分配, m个队列, n个消费者, 每个消费者分配m%n=i的队列.
* AllocateMessageQueueByConfig: 用户自定义设置队列.
* AllocateMessageQueueByMachineRoom: 选择相同机房然后平均分配队列.
* AllocateMachineRoomNearby: 先选择相同机房然后平均分配队列, 然后将剩余的队列通过自定义策略继续分配给所有的消费者.
* AllocateMessageQueueConsistentHash: 一致性哈希分配: 消费者节点构建虚拟节点, 默认计算队列的key的MD5值找到第一个比它大的消费者节点消费该队列.

=== RabbitMQ

[qanda]
AMQP协议的流程?::
. 消息先从生产者Producer出发到达交换器Exchange.
. 交换器Exchange根据路由规则将消息转发对应的队列Queue之上.
. 消息在队列Queue上进行存储.
. 消费者Consumer订阅队列Queue并进行消费.
如何保证消息投递成功?::
* 本地事务表:
. 消息生产者发送消息时保存业务数据和消息到db中, 状态为 *已发送* .
. 消息接收者处理完消息后更改消息状态为 *已接收* .
. 定时任务轮询 *已发送* 的消息重新发送.
* 延时二次确认:
. 消息生产者发送消息时再向 _callback server_ 发送一条延时消息.
. 消息接收者处理完消息后向 _callback server_ 立即发送一条确认消息.
. _callback server_ 收到确认消息后记录到DB.
. _callback server_ 来自生产者的延时消息后查询DB是否存在该条消息, 如果不存在则通知生产者消息没有收到.
RabbitMQ有哪些角色?::
* Queue: 存放消息的容器.
* Exchange: 接收来自生产者的消息, 然后将消息路由到不同的队列.
* Routing Key: 生产者将消息发送给Exchange的时候一般会指定一个Routing Key.
* Binding: RabbitMQ中通过绑定将Exchange和队列关联起来, 绑定的时候会指定一个Binding Key.
RabbitMQ的消息是怎么发送的?::
. 生产者将消息发送给Exchange, 并指定一个Routing Key.
. RabbitMQ根据Exchange的类型和与队列绑定的Binding Key去和Routing Key匹配找到相应的队列.
. RabbitMQ将消息路由到队列里.
RabbitMQ的Exchange类型?::
* direct: 将消息路由到BindingKey和RoutingKey相同的队列.
* fanout: 将发送到该Exchange的消息路由到所有与之绑定的所有队列.
* topic: 根据RoutingKey匹配BindingKey路由到匹配的队列.
** `.` 号用于匹配一个单词
** `#` 号用于匹配0个或多个单词
* headers: 根据headers匹配队列而不是RoutingKey和BindingKey.
RabbitMQ中vhost的作用是什么?::
实现租户隔离.
RabbitMQ怎么实现延迟消息队列?::
* 发送ttl消息到一个队列, 然后监听这个队列的死信队列.
* 使用插件 `rabbitmq_delayed_message_exchange` , 直接创建一个延迟队列.
RabbitMQ消息的状态?::
* Ready: 消息进入队列等待消费.
* Unacked: 消息被消费且未受到Ack确认.
* Acked: 消息被消费且受到Ack确认, 即将删除.
* Rejected: 消费者拒绝消息并不希望重新放回队列, 即将进入死信队列.
* Delayed: TTL消息.
* Expired: TTL消息过期, 即将进入死信队列.
RabbitMQ消息存储的方式?::
* alpha: 消息内容和消息索引都存放在内存中.
* beta: 消息索引存放在内存中, 消息内容存放在磁盘上.
* gamma: 消息索引在内存和磁盘上, 消息内容存放在磁盘上.
* delta: 消息索引和消息内容都在磁盘上.
alpha状态只需要在内存中读取消息, delta状态需要两次I/O操作, beta和gamma状态需要一次I/O.

=== Kafka

[qanda]
生产者acks值含义?::
* 0: 生产者不等待broker对消息的确认, 返回的消息偏移量固定为-1.
* 1: 消息写入到主分区, 然后返回, 不等待副本分区的确认.
* -1: 主分区会同步给副本分区然后等待所有副本分区的确认, 再返回.
Kafka分区的方式?::
* Default(默认): 如果key为null, 则随机分配到某个分区, 并且下次还是这个分区, 如果不为null则计算key的哈希码再计算分区号.
* RoundRobin: 轮番分配到每个分区.
* Sticky: 随机分配到某个分区, 并且下次还是这个分区.
Kafka为消费者分配分区的方式?::
* Range(默认): 分别对分区和消费者排序, 计算每个消费者应该消费多少分区, 再依次分配给消费者, 如10个分区3个消费者: `[1 2 3 4,5 6 7,8 9 10]`
* RoundRobin: 将所有主题+分区组合起来排序, 再将消费者排好序, 然后将每个主题每个分区依次分配给消费者, 如两个主题, 10+2个分区3个消费者: `[1 4 7 10,2 5 8 2-1,3 6 9 2-2]`
* Sticky: 先按照RoundRobin分配, 如果某一个消费者下线了, 仅将这个消费者之前消费的分区按照RoundRobin依次分配给剩余的消费者.

== Docker

[qanda]
Linux namespace类型有哪些?::
* UTS: 主机名和域名
* IPC: 进程通信资源.
* Mount: 文件挂载.
* PID: 进程pid.
* Network: 网卡.
* User: 用户和用户组.
Docker的实现原理?::
* 资源隔离 `namespace` : 隔离环境.
* 资源配额 `cgroup` : 控制资源配额 (cgroupV1限制不了Buffer IO, V2可以)
* 文件系统 `UnionFS` : 将不同位置的目录联合挂载到同一个目录下, 文件分层, 具体实现有overlay2/zfs/vfs.
* 网络驱动: 设置虚拟网卡, 实现网络隔离和端口映射.
* 执行引擎: 管理容器的生命周期, 如创建, 启动, 停止.
* 镜像管理: 镜像系统支持分层构建和增量更新, 提供Registry用于存储和分发镜像.
Docker支持哪些网络类型?::
* bridge
* host
* ipvlan
* macvlan
* overlay
* null
Docker文件持久化存储方式?::
* 创建volume
* 宿主机目录挂载到容器里.
如何限制容器内存和CPU最大用量?::
* 限制内存使用量: `-m=100m` 表示容器最多可使用100MB的内存.
* 限制cpu使用率: `--cpus="1.5"` 表示容器可以达到 stem:[150%] 的CPU使用率(8核的话最大使用率为 stem:[800%]).
`COPY` 和 `ADD` 指令的区别?::
* `ADD` 会自动解压压缩包, 然后复制到指定目录, `COPY` 不支持自动解压.
* `ADD` 支持下载URL文件到指定目录, `COPY` 只支持本地文件或目录.
`CMD` 和 `ENTRYPOINT` 指令的区别?::
* `CMD` 只能在容器启动时被命令行参数覆盖, `ENTRYPOINT` 可以在容器启动时追加传递参数.
* `CMD` 可以声明多个, 但是只有最后一个会生效, `ENTRYPOINT` 在 _EXEC_ 模式(数组)下可以和 `CMD` 混用, `CMD` 作为 `ENTRYPOINT` 的参数传递过去.

== 网络

[qanda]
TCP三次握手的过程?::
. 客户端向服务端发送SYN包.
. 服务端向客户端发送ACK+SYN包.
. 客户端向服务端发送ACK包.
为什么需要三次握手而不是两次?::
服务端也需要向客户端证明自己的发消息能力, 所以服务端也需要发SYN包确保客户端能收到.
为什么需要三次握手而不是四次?::
握手流程未完成, 此时应用程序还没有开始发送数据包, 所以ACK包可以和SYN包合并发送.
TCP四次挥手的过程?::
. 客户端向服务端发送FIN包, 通知自己想要关闭连接.
. 服务端收到后回复一个ACK包.
. 服务端处理完数据后, 向客户端发送FIN包.
. 客户端收到后回复一个ACK包.
为什么从TIME-WAIT到CLOSE状态需要等两个MSL?::
保证服务端收到ACK包, 如果服务端没收到会重发FIN包, 这个过程会耗时两个MSL.
有哪些对称加密算法?::
* AES
* 3DES
* DES
有哪些非对称加密算法?::
* RSA
* DSA
有哪些消息摘要哈希算法?::
* SHA
* MD5
* MAC
HTTPS协议的协商过程?::
. 客户端发送给服务端一个报文, 包含TLS版本号, 支持的加密方法, 一个随机数A.
. 服务端收到后, 返回给客户端HTTPS证书公钥, 使用的加密方法和一个随机数B.
. 客户端先向CA验证HTTPS证书是否合法, 然后又生成一个随机数C使用服务端公钥加密, 发送给服务端.
. 服务端使用自己的私钥解密, 用之前协商的加密方法对随机数ABC计算出一个秘钥, 此后所有的报文都使用这个对称秘钥加解密.
. 客户端也用同样的加密方法对三个随机数计算得到相同的秘钥, 此后的报文使用该对称秘钥加解密.
正向代理和反向代理的区别?::
* 正向代理为客户端服务, 代理客户端请求服务器, 服务器并不知道这个请求是由哪个客户端发起的.
* 反向代理为服务端服务, 客户端请求反向代理服务器获取数据, 客户端并不知道请求是哪个最终的服务器响应的.

== 网关

=== Nginx

[qanda]
Nginx反向代理路径配置方式?::
* 精确匹配: `location = /api`
* 匹配路径前缀, 匹配到立即返回: `location ^~ /api`
* 不区分大小写的正则匹配: `location ~* /api`
* 正则匹配: `location ~ /api`
* 匹配路径前缀: `location /api`
Nginx负载均衡策略?::
* 轮询(默认): 请求被逐一分配到每个下游服务上.
* 权重: 权重越高的下游服务, 被分配的请求数越多.
* ip_hash: 每个请求按照IP计算哈希值固定分配到某一个下游服务上.
* fair: 按照服务响应时间分配请求, 响应时间越短的下游服务被分配的请求越多.
* url_hash: 每个请求按照URL计算哈希值固定分配到某一个下游服务上
* consist_hash: 一致性哈希, 根据url/ip/参数计算出来的哈希值分配节点.
Nginx下游服务配置参数?::
* down: 表示该服务不参与负载.
* weight: 设置服务权重, 默认为1, 权重越高被分配的请求数越多
* max_fails: 允许请求失败的最大次数.
* fail_timeout: max_fail次请求失败后, 暂停代理该服务的时长.
* backup: 其他非backup服务忙或者下线的时候, 再请求该服务.
request_time和upstream_response_time的区别?::
* request_time: 从Nginx开始接收请求到返回响应完成的整体时间.
* upstream_connect_time: Nginx跟上游建立连接花费的时间.
* upstream_header_time: Nginx从建立上游连接到接收完上游返回的header花费的时间.
* upstream_response_time: Nginx从建立上游连接到接收完上游返回的header+body花费的时间.
* 上游处理花费的时间: upstream_header_time - upstream_connect_time.

== Linux

[qanda]
查看当前机器IP?::
`hostname -I | tr " " "\n" | head -1`
如何批量杀死进程?::
`pgrep xx | xargs kill -9`
介绍下select, poll, epoll?::
* select: 将文件句柄数组复制到内核空间, 如果有文件句柄就绪, 则函数调用返回, 应用程序遍历数组, 判断是否有自己需要的事件,
** 优点: 跨平台兼容性好.
** 缺点: linux限制文件句柄数组长度最大为1024, 且线性遍历数组全部元素, 效率较低.
* poll: 将文件句柄数组改为链表, 解决文件句柄数量限制的问题.
** 优点: 解决文件句柄数量限制问题.
** 缺点: 应用程序每次仍然全量遍历, 效率不高.
* epoll: 将文件句柄复制给内核并注册感兴趣的事件, 让内核去遍历, 然后只通知存在事件的文件句柄, 应用程序不需要全量遍历.
** LT模式: 如果文件句柄上的字节流没读完, 下次还会通知.
** ET模式: 每个文件句柄最多只通知一次, 无论应用程序有没有读完.
普通io, mmap和sendfile读写的区别?::
* 普通io:
. 用户态切换到内核态, 内核将磁盘文件DMA读取(避免消耗CPU资源)到内核缓冲区.
. 内核缓冲区数据复制到用户缓冲区.
. read返回, 内核态切换到用户态.
. 用户态写数据, 调用write, 切换到内核态, 将用户缓冲区拷贝到Socket缓冲区.
. Socket缓冲区数据DMA复制到网卡.
. write返回, 内核态切换到用户态.
. 一共4次上下文切换, 4次拷贝.
* mmap+write:
. 用户态切换到内核态, 内核将磁盘文件DMA读取到内核缓冲区, 同时将该内核缓冲区映射到用户缓冲区.
. 内核态切换到用户态.
. 用户态写数据, 切换到内核态, 内核将缓冲区数据CPU拷贝到Socket缓冲区.
. Socket缓冲区DMA复制数据到网卡.
. 内核态切换到用户态.
. 一共4次上下文切换, 3次拷贝.
* sendfile:
. 用户态切换到内核态, 内核将磁盘文件DMA读取到内核缓冲区.
. 内核态切换回用户态, 从内核缓冲区直接将数据DMA拷贝到网卡.
. 一共2次上下文切换, 2次拷贝.
* mmap适用于小文件频繁修改, sendfile适用于大文件网络传输.


== 分布式

[qanda]
CAP定理?::
* C: 一致性(Consistency) 所有节点访问数据时都是同一份最新的副本.
* A: 可用性(Availability) 每次请求都能得到响应, 但不一定是最新的数据.
* P: 分区容错性(Partition Tolerance) 在遇到网络分区故障的时候, 仍然能对外提供满足一致性和可用性的服务, 除非整个分布式系统网络全部故障.
什么是一致性?::
* 强一致性: 所有节点的数据状态始终保持一致.
* 弱(最终)一致性: 数据一致性会有延迟, 但保证未来会有一个时刻保证数据一致性.
分布式事务的实现方式?::
* 强一致性
** 2PC
** 3PC
** TCC
* 最终一致性
** Saga
** 本地消息表
** RocketMQ事务消息
2PC流程?::
. prepare commit: 事务协调者向每个事务参与者发送prepare commit请求, 每个事务参与者开启事务并执行业务逻辑.
. do commit/rollback: 事务协调者向每个事务参与者发送do commit请求, 每个事务参与者提交事务.
. 如果在prepare commit阶段事务参与者存在报错, 事务协调者向每个事务参与者发送取消/rollback请求.
3PC流程?::
. can commit: 事务协调者向每个事务参与者发送can commit请求, 如果存在事务参与者响应正常则进行下一个阶段.
. prepare commit: 事务协调者向每个事务参与者发送prepare commit请求, 每个事务参与者开启事务并执行业务逻辑.
. do commit/rollback: 事务协调者向每个事务参与者发送do commit请求, 每个事务参与者提交事务.
. 如果在can commit/prepare commit阶段事务参与者存在报错, 事务协调者向每个事务参与者发送rollback请求.
TCC流程?::
. 事务参与者定义好Try/Confirm/Cancel方法.
. Try: 事务协调者通知所有事务参与者执行Try方法, 检查业务可行性或者尝试执行业务逻辑(例: 插入enabled=0数据/删除数据前取出来冻结数据/检查数据是否存在), 如果检查未通过则执行Cancel方法.
. Confirm: 执行业务逻辑(例: enabled设置成1/执行删除逻辑), 提交事务.
* Cancel: 如果存在事务参与者存在报错, 则事务协调者通知所有事务参与者执行Cancel方法回滚事务.
Saga流程?::
. 事务参与者定义好执行初始事务和补偿事务的方法.
. 事务协调者通知所有事务参与者执行初始事务并提交.
. 如果有事务参与者执行报错, 则通知所有事务参与者执行补偿事务.
TCC和Saga的区别?::
* TCC的事务粒度比较小, 仅需针对Try或者Try+Confirm的操作进行回滚; Saga需要回滚整个操作的事务.
* TCC同步阻塞, Saga异步非阻塞.
* TCC保证强一致性, Saga只保证最终一致性.
分布式锁的使用场景?::
* 避免不同的节点执行相同的任务, 如定时任务, 批处理任务.
* 避免不同的节点读取到同一条数据, 避免数据竞争导致数据不一致的问题.
* 分布式事务管理.
* 分布式限流.
分布式锁的实现方式?::
* 基于关系型数据库: 在拥有唯一索引或主键索引的基础上插入数据, 插入成功则获取锁成功; 释放锁时删除数据.
* 基于kv数据库: 获取锁时在kv库中插入一个带时效时间的键值对, 不存在则插入成功, 表示获取锁成功; 释放锁时删除该键值对.
** Redis:
. 加锁: `SET key value NX PX expire_ms` .
. 新建一个定时任务续约锁的超时时间.
. 释放锁: 判断是否是当前线程持有锁, 如果是则删除key.
+
[source, lua]
----
if redis.call("GET", KEYS[1]) == ARGV[1] then
    return redis.call("DEL",KEYS[1])
    else
return 0
end
----
+
** etcd:
. 为同一把锁定义一个目录/locks/, 每个线程在这里目录下put数据, key为/locks[/业务id]/随机UUID, TTL为业务预估时间, 如果业务超时且需要续约的场景可以创建一个定时任务续约该key的TTL.
. 查询该目录下所有kv, 比较版本号:
.. 如果当前key的版本号最小, 则获取锁成功, 执行业务逻辑.
.. 如果当前key的版本号不是最小, 则watch前一个版本号的key进入阻塞状态.
.. watch返回则说明上一个锁释放且当前线程获取锁成功, 执行业务逻辑.
. 执行完业务逻辑需释放锁, 删除当前key.
. etcdv3自带lock/unlock命令, 可直接使用, 如果业务超时且需要续约的场景可以创建一个定时任务续约lock生成的key的TTL.
Basic Paxos的各个角色?::
* Client(民众): 系统外部角色, 请求发起者.
* Proposer(议员): 接收Client请求, 向集群提出提议.
* Acceptor(国会): 提议投票和提议接收者, 只有多数派接受时, 提议才会被最终接受.
* Learner(记录员): 记录被通过的提议.
Basic Paxos流程?::
. Proposer收到Client请求发送给Acceptor提案n.
. 如果大多数Acceptor同意对提案n投票, 则通知Proposer.
. Proposer通知Acceptor提案n.
. Acceptor接受提案n, 通知Learner和Proposer.
Multi Paxos角色?::
相对于Basic Paxos, 多了Leader这个角色, Leader即拥有一票否决确定权的Acceptor, 所有的请求都需要经过此Leader.
Multi Paxos流程?::
. Proposer向Acceptor发出请求, 确定Leader节点.
. Proposer收到Client请求后直接向Leader发送提议, Leader通过提议, 通知其他的Acceptor和Learner.
Multi Paxos 相比较Basic Paxos少了一次调用流程.
Raft的各个角色?::
* Leader: 集群主节点, 统一接收请求并同步到Follower, 同时定时发送心跳包给Follower节点.
* Candidate: 可以竞选成为Leader节点的候选节点, Follower想变成Leader必须先变成Candidate, 然后让其他集群节点投票.
* Follower: 接受Leader请求同步日志, 对客户端提供读请求服务, 如果在一定超时时间内没有收到Leader的心跳包, 则会升级为Candidate节点竞选, 竞选投票最多的节点会成为新的Leader节点.
Raft日志复制流程?::
. Leader收到客户端请求, 本地写日志.
. Leader同步日志给其他节点.
. Leader本地提交, 通知其他节点提交.


== 场景问题

[qanda]
订单超时如何关闭?::
* 定时任务扫描
* MQ延迟消息
* Redisson RDelayedQueue
如何防止用户重复提交表单?::
* 前端按钮点击后置灰.
* 前端页面加载时从后端服务取到token, 提交表单时带上token, 后端校验该token是否已经被使用过.
* 对于插入操作, 数据库表加唯一索引; 对于更新操作, 数据库表加乐观锁列.
* by用户id限流, 限制1秒只能提交一次该接口的请求.
如何设计一个秒杀系统?::
* 性能:
** 前端静态资源和待秒杀的商品数据提前渲染生成页面放到CDN上, 保证页面加载速度.
** 查询接口使用长TTL分布式缓存+短TTL本地缓存, 并提前预热缓存数据.
** 为秒杀相关服务单独部署, 提前做好性能测试预估机器配额, 防止影响其他普通交易.
** 库存表拆分为多个子表来降低update行锁的并发性能, 或者插入订单流水数据来校验库存, 然后发异步消息扣减库存.
* 安全:
** 接入层添加IP或者设备限流/waf防御等功能, 前后端可以使用csrf token机制, 阻止恶意请求, .
** 业务上可以设计成用户预约后才能参与秒杀, 降低风险.
** 页面上集成验证码.
* 一致性:
** 下单后生成订单流水日志数据以核对校验数据, 如禁止重复下单/库存校验等.
** 扣减库存使用分布式锁或者Redis lua脚本来实现.
如何实现排行榜功能?::
使用Redis ZSet来实现, value为用户id, score为用户积分.
如果积分相同的情况下需按照时间排序, 则score可以将时间戳作为小数位存储, 这样可以按时间倒序获取排行, 如果要按时间顺序则小数位可以用(10e11-时间戳)来实现.
* `zadd <key> <score> <user_id>` : 向排行榜添加/更新用户数据.
* `zrevrange <key> <from> <to> withscores` : 获取排行榜第from~to的用户和积分数据.
* `zrank <key> <user_id>` : 获取指定用户的排名.
* `zrem <key> <user_id>` : 删除指定用户的数据.
* `zscore <key> <user_id>` : 获取指定用户的积分数据.
如何实现附近的人功能?::
* 使用Redis的geo数据类型实现.
** `geoadd <key> <longitude> <latitude> <user_id>` : 添加用户经纬度数据.
** `geopos <key> <user_id>` : 获取指定用户的经纬度数据.
** `georadius <key> <longitude> <latitude> <radius> m|km|ft|mi withcoord withdist` : 获取指定经纬度radius半径内的用户数据, 包含经纬度和距离.
限流算法有哪些?::
* 固定窗口: 计数器.
. 记录上次请求时间和请求数.
. 请求到达时, 用当前时间减去上次请求时间, 如果大于窗口则重置计数器, 否则请求数加1.
. 判断请求数是否超过限流值, 如果超过则限流.
. 更新上次请求时间为当前时间.
* 滑动窗口: 环形队列.
. 将时间区间划分为N个窗口, 组成环形队列, 并记录上次请求时间.
. 请求到达后, 用(当前时间-上次请求时间)/窗口时长=这段时间的窗口数M, 将M-N外的窗口计数置0.
. 计算当前时间所处的窗口, 该窗口请求数加1.
. 对队列内的请求数统计求和得到时间区间内的请求数, 判断是否超过限流值.
* 漏斗:
. 定义:
** burst: 漏斗容量.
** rate: 漏斗允许的流出速率.
** excess: 漏斗剩余的数据量, 初始为0.
** lastTimestamp: 上次请求的时间戳.
. 请求到达后, 计算当前漏斗数据量: `excess = max(excess - rate * (currentTimestamp - lastTimestamp) + 1, 0)` .
. 如果漏斗剩余的数据量excess大于burst, 则需要限流; 如果在0~burst区间内, 需要延迟 `excess/burst` 秒再放行请求; 如果excess为0则直接放行请求.
* 令牌桶:
. 定义
** capacity: 令牌桶容量.
** rate: 令牌流入速率.
** tokens: 令牌桶剩余的令牌量, 初始为capacity.
** lastTimestamp: 上次请求的时间戳.
. 请求到达后, 计算当前令牌桶剩余的令牌量: `tokens = min(tokens + rate * (currentTimestamp - lastTimestamp), capacity)` .
. 如果剩余的令牌量tokens是否为0, 则需要限流.
